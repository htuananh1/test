import os
import re
import asyncio
import io
import logging
import random
import datetime
import base64
import json
from typing import Optional, Dict, List, Tuple, Any, Union
from collections import deque, defaultdict
from dataclasses import dataclass, field
from enum import Enum
import time
import aiohttp
from PIL import Image
import requests

from telegram import Update, InlineKeyboardButton, InlineKeyboardMarkup
from telegram.constants import ParseMode, ChatAction
from telegram.ext import (
    ApplicationBuilder, 
    ContextTypes, 
    MessageHandler, 
    filters, 
    CommandHandler, 
    CallbackQueryHandler
)
from telegram.error import BadRequest, TimedOut, NetworkError
from openai import OpenAI

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger("linh_bot")

# Constants for Vietnam features
VIETNAM_TIMEZONES = {
    "hanoi": "Asia/Ho_Chi_Minh",
    "saigon": "Asia/Ho_Chi_Minh", 
    "danang": "Asia/Ho_Chi_Minh"
}

VIETNAM_HOLIDAYS = {
    "01-01": "Táº¿t DÆ°Æ¡ng Lá»‹ch",
    "30-04": "NgÃ y Giáº£i phÃ³ng miá»n Nam",
    "01-05": "NgÃ y Quá»‘c táº¿ Lao Ä‘á»™ng",
    "02-09": "NgÃ y Quá»‘c khÃ¡nh"
}

VIETNAM_CITIES = {
    "hanoi": {"name": "HÃ  Ná»™i", "lat": 21.0285, "lon": 105.8542},
    "hcm": {"name": "TP.HCM", "lat": 10.8231, "lon": 106.6297},
    "danang": {"name": "ÄÃ  Náºµng", "lat": 16.0544, "lon": 108.2022},
    "haiphong": {"name": "Háº£i PhÃ²ng", "lat": 20.8449, "lon": 106.6881},
    "cantho": {"name": "Cáº§n ThÆ¡", "lat": 10.0452, "lon": 105.7469},
    "nhatrang": {"name": "Nha Trang", "lat": 12.2388, "lon": 109.1967},
    "dalat": {"name": "ÄÃ  Láº¡t", "lat": 11.9404, "lon": 108.4583},
    "hue": {"name": "Huáº¿", "lat": 16.4637, "lon": 107.5909}
}

@dataclass
class Config:
    BOT_TOKEN: str = field(default_factory=lambda: os.getenv("BOT_TOKEN", ""))
    VERCEL_API_KEY: str = field(default_factory=lambda: os.getenv("VERCEL_API_KEY", ""))
    BASE_URL: str = field(default_factory=lambda: os.getenv("BASE_URL", "https://ai-gateway.vercel.sh/v1"))
    
    # Text models (Vercel)
    CHAT_MODEL: str = field(default_factory=lambda: os.getenv("CHAT_MODEL", "anthropic/claude-3.5-haiku"))
    CODE_MODEL: str = field(default_factory=lambda: os.getenv("CODE_MODEL", "anthropic/claude-3.5-sonnet"))
    FILE_MODEL: str = field(default_factory=lambda: os.getenv("FILE_MODEL", "anthropic/claude-3.5-sonnet"))
    
    # Gemini models
    GEMINI_API_KEY: str = field(default_factory=lambda: os.getenv("GEMINI_API_KEY", ""))
    GEMINI_TEXT_MODEL: str = field(default_factory=lambda: os.getenv("GEMINI_TEXT_MODEL", "gemini-2.0-flash-exp"))
    GEMINI_VISION_MODEL: str = field(default_factory=lambda: os.getenv("GEMINI_VISION_MODEL", "gemini-1.5-flash"))
    GEMINI_IMAGE_GEN_MODEL: str = field(default_factory=lambda: os.getenv("GEMINI_IMAGE_GEN_MODEL", "gemini-2.0-flash-preview-image-generation"))
    
    MAX_TOKENS: int = field(default_factory=lambda: int(os.getenv("MAX_TOKENS", "1200")))
    MAX_TOKENS_CODE: int = field(default_factory=lambda: int(os.getenv("MAX_TOKENS_CODE", "4000")))
    FILE_OUTPUT_TOKENS: int = field(default_factory=lambda: int(os.getenv("FILE_OUTPUT_TOKENS", "6000")))
    
    CHUNK_CHARS: int = field(default_factory=lambda: int(os.getenv("CHUNK_CHARS", "120000")))
    PAGE_CHARS: int = field(default_factory=lambda: int(os.getenv("PAGE_CHARS", "3200")))
    CTX_TURNS: int = field(default_factory=lambda: int(os.getenv("CTX_TURNS", "15")))
    REQUEST_TIMEOUT: float = field(default_factory=lambda: float(os.getenv("REQUEST_TIMEOUT", "90")))
    
    WEATHER_API_KEY: str = field(default_factory=lambda: os.getenv("WEATHER_API_KEY", ""))
    NEWS_API_KEY: str = field(default_factory=lambda: os.getenv("NEWS_API_KEY", ""))
    
    CACHE_TTL: int = 3600
    MAX_CACHE_SIZE: int = 100

config = Config()

# Import Google AI libraries
try:
    import google.generativeai as genai
    GENAI_AVAILABLE = True
except ImportError:
    genai = None
    GENAI_AVAILABLE = False
    logger.warning("google-generativeai not installed")

# Import optional libraries
try:
    import chardet
except ImportError:
    chardet = None

try:
    import PyPDF2
except ImportError:
    PyPDF2 = None

try:
    import docx
    from docx import Document as DocxDocument
except ImportError:
    docx = None
    DocxDocument = None

try:
    import openpyxl
except ImportError:
    openpyxl = None

try:
    from pptx import Presentation
except ImportError:
    Presentation = None

try:
    from bs4 import BeautifulSoup
except ImportError:
    BeautifulSoup = None

class FileType(Enum):
    TEXT = "text"
    CODE = "code"
    PDF = "pdf"
    DOCX = "docx"
    XLSX = "xlsx"
    PPTX = "pptx"
    HTML = "html"
    JSON = "json"
    CSV = "csv"
    IMAGE = "image"
    ARCHIVE = "archive"
    UNKNOWN = "unknown"

ARCHIVES = (".zip", ".rar", ".7z", ".tar", ".tar.gz", ".tgz", ".tar.bz2", ".tar.xz")
TEXT_LIKE = (
    ".txt", ".md", ".log", ".csv", ".tsv", ".json", ".yaml", ".yml", 
    ".ini", ".cfg", ".env", ".xml", ".html", ".htm"
)
CODE_EXTENSIONS = (
    ".py", ".js", ".ts", ".java", ".c", ".cpp", ".cs", ".go", 
    ".php", ".rb", ".rs", ".sh", ".bat", ".ps1", ".sql", ".swift",
    ".kt", ".scala", ".r", ".m", ".dart", ".lua", ".pl", ".asm"
)
IMAGE_EXTENSIONS = (".jpg", ".jpeg", ".png", ".gif", ".bmp", ".webp", ".svg", ".ico")

@dataclass
class ImageData:
    """Store image data for analysis"""
    file_id: str
    file_data: bytes
    caption: Optional[str] = None
    timestamp: float = field(default_factory=time.time)

@dataclass
class UserState:
    history: deque = field(default_factory=lambda: deque(maxlen=32))
    file_mode: bool = False
    image_mode: bool = False
    pending_file: Optional[Dict[str, Any]] = None
    pending_images: List[ImageData] = field(default_factory=list)
    last_result: str = ""
    active_messages: Dict[int, Any] = field(default_factory=dict)
    language: str = "vi"
    location: Optional[str] = "hanoi"

class BotState:
    def __init__(self):
        self.users: Dict[int, UserState] = defaultdict(UserState)
        self.pagers: Dict[Tuple[int, int], Dict] = {}
        self.cache: Dict[str, Tuple[Any, float]] = {}
        
    def get_user(self, chat_id: int) -> UserState:
        return self.users[chat_id]
    
    def cache_get(self, key: str) -> Optional[Any]:
        if key in self.cache:
            value, timestamp = self.cache[key]
            if time.time() - timestamp < config.CACHE_TTL:
                return value
            del self.cache[key]
        return None
    
    def cache_set(self, key: str, value: Any):
        if len(self.cache) >= config.MAX_CACHE_SIZE:
            oldest_key = min(self.cache.keys(), key=lambda k: self.cache[k][1])
            del self.cache[oldest_key]
        self.cache[key] = (value, time.time())

bot_state = BotState()

class VietnamServices:
    """Services related to Vietnam"""
    
    @staticmethod
    async def get_weather(city: str) -> str:
        """Get weather for Vietnamese cities"""
        if not config.WEATHER_API_KEY:
            return "âŒ Thiáº¿u API key thá»i tiáº¿t. LiÃªn há»‡ @cucodoivandep"
        
        city_info = VIETNAM_CITIES.get(city.lower())
        if not city_info:
            cities = ", ".join(VIETNAM_CITIES.keys())
            return f"âŒ KhÃ´ng tÃ¬m tháº¥y {city}\nCÃ¡c thÃ nh phá»‘ há»— trá»£: {cities}"
        
        try:
            url = f"https://api.openweathermap.org/data/2.5/weather"
            params = {
                "lat": city_info["lat"],
                "lon": city_info["lon"],
                "appid": config.WEATHER_API_KEY,
                "units": "metric",
                "lang": "vi"
            }
            
            async with aiohttp.ClientSession() as session:
                async with session.get(url, params=params) as response:
                    data = await response.json()
                    
            temp = data["main"]["temp"]
            feels_like = data["main"]["feels_like"]
            humidity = data["main"]["humidity"]
            description = data["weather"][0]["description"]
            wind_speed = data.get("wind", {}).get("speed", 0)
            
            weather_emoji = "â˜€ï¸" if temp > 30 else "â›…" if temp > 20 else "ğŸŒ§ï¸"
            
            return (
                f"{weather_emoji} **Thá»i tiáº¿t {city_info['name']}**\n\n"
                f"ğŸŒ¡ Nhiá»‡t Ä‘á»™: {temp}Â°C (cáº£m giÃ¡c {feels_like}Â°C)\n"
                f"ğŸ’§ Äá»™ áº©m: {humidity}%\n"
                f"ğŸ’¨ GiÃ³: {wind_speed} m/s\n"
                f"â˜ï¸ Trá»i: {description.capitalize()}\n\n"
                f"ğŸ’¡ Gá»£i Ã½: {'Nhá»› mang Ã´ â˜‚ï¸' if 'mÆ°a' in description.lower() else 'Thá»i tiáº¿t Ä‘áº¹p Ä‘á»ƒ Ä‘i chÆ¡i! ğŸŒº'}"
            )
        except Exception as e:
            return f"âŒ Lá»—i láº¥y thá»i tiáº¿t: {str(e)[:100]}"
    
    @staticmethod
    async def get_exchange_rate() -> str:
        """Get USD/VND exchange rate"""
        try:
            url = "https://api.exchangerate-api.com/v4/latest/USD"
            async with aiohttp.ClientSession() as session:
                async with session.get(url) as response:
                    data = await response.json()
            
            vnd_rate = data["rates"].get("VND", 0)
            eur_rate = 1 / data["rates"].get("EUR", 1)
            gbp_rate = 1 / data["rates"].get("GBP", 1)
            jpy_rate = data["rates"].get("JPY", 0)
            cny_rate = data["rates"].get("CNY", 0)
            
            date = data.get("date", "")
            
            return (
                f"ğŸ’± **Tá»· giÃ¡ hÃ´m nay** ({date})\n\n"
                f"ğŸ‡ºğŸ‡¸ 1 USD = **{vnd_rate:,.0f}** VND\n"
                f"ğŸ‡ªğŸ‡º 1 EUR = **{vnd_rate * eur_rate:,.0f}** VND\n"
                f"ğŸ‡¬ğŸ‡§ 1 GBP = **{vnd_rate * gbp_rate:,.0f}** VND\n"
                f"ğŸ‡¯ğŸ‡µ 100 JPY = **{vnd_rate * 100 / jpy_rate:,.0f}** VND\n"
                f"ğŸ‡¨ğŸ‡³ 1 CNY = **{vnd_rate / cny_rate:,.0f}** VND\n\n"
                f"ğŸ“ˆ VÃ ng SJC: ~92,000,000 VND/lÆ°á»£ng"
            )
        except Exception as e:
            return f"âŒ Lá»—i láº¥y tá»· giÃ¡: {str(e)[:100]}"
    
    @staticmethod
    def get_vietnam_time() -> str:
        """Get current time in Vietnam"""
        try:
            import pytz
            vn_tz = pytz.timezone('Asia/Ho_Chi_Minh')
            vn_time = datetime.datetime.now(vn_tz)
            
            # Vietnamese day names
            vn_days = ['Thá»© Hai', 'Thá»© Ba', 'Thá»© TÆ°', 'Thá»© NÄƒm', 'Thá»© SÃ¡u', 'Thá»© Báº£y', 'Chá»§ Nháº­t']
            day_name = vn_days[vn_time.weekday()]
            
            # Check if today is a holiday
            date_str = vn_time.strftime("%d-%m")
            holiday = VIETNAM_HOLIDAYS.get(date_str, "")
            
            # Calculate lunar calendar (approximate)
            lunar_info = "ğŸŒ™ Ã‚m lá»‹ch: Äang cáº­p nháº­t"
            
            time_str = (
                f"ğŸ‡»ğŸ‡³ **Giá» Viá»‡t Nam**\n\n"
                f"ğŸ“… {day_name}, {vn_time.strftime('%d/%m/%Y')}\n"
                f"ğŸ• {vn_time.strftime('%H:%M:%S')} (GMT+7)\n"
                f"{lunar_info}"
            )
            
            if holiday:
                time_str += f"\n\nğŸ‰ **{holiday}**"
            
            # Add greeting based on time
            hour = vn_time.hour
            if 5 <= hour < 11:
                greeting = "ğŸŒ… ChÃ o buá»•i sÃ¡ng!"
            elif 11 <= hour < 13:
                greeting = "â˜€ï¸ ChÃ o buá»•i trÆ°a!"  
            elif 13 <= hour < 18:
                greeting = "ğŸŒ¤ ChÃ o buá»•i chiá»u!"
            else:
                greeting = "ğŸŒ™ ChÃ o buá»•i tá»‘i!"
            
            time_str += f"\n\n{greeting}"
            
            return time_str
        except:
            vn_time = datetime.datetime.utcnow() + datetime.timedelta(hours=7)
            return f"ğŸ• Giá» VN: {vn_time.strftime('%H:%M:%S %d/%m/%Y')}"
    
    @staticmethod
    async def get_news() -> str:
        """Get Vietnamese news headlines"""
        if not config.NEWS_API_KEY:
            # Return some default news sources
            return (
                "ğŸ“° **BÃ¡o chÃ­ Viá»‡t Nam**\n\n"
                "ğŸ”¸ VnExpress: vnexpress.net\n"
                "ğŸ”¸ Tuá»•i Tráº»: tuoitre.vn\n"
                "ğŸ”¸ Thanh NiÃªn: thanhnien.vn\n"
                "ğŸ”¸ DÃ¢n TrÃ­: dantri.com.vn\n"
                "ğŸ”¸ VTC News: vtc.vn\n\n"
                "ğŸ’¡ Cáº§n API key Ä‘á»ƒ xem tin tá»©c tá»± Ä‘á»™ng"
            )
        
        try:
            url = "https://newsapi.org/v2/top-headlines"
            params = {
                "country": "vn",
                "apiKey": config.NEWS_API_KEY,
                "pageSize": 5
            }
            
            async with aiohttp.ClientSession() as session:
                async with session.get(url, params=params) as response:
                    data = await response.json()
            
            if data.get("status") != "ok":
                return "âŒ KhÃ´ng láº¥y Ä‘Æ°á»£c tin tá»©c"
            
            articles = data.get("articles", [])
            if not articles:
                return "ğŸ“° KhÃ´ng cÃ³ tin tá»©c má»›i"
            
            news_text = "ğŸ“° **Tin tá»©c Viá»‡t Nam má»›i nháº¥t**\n\n"
            for i, article in enumerate(articles[:5], 1):
                title = article.get("title", "")
                description = article.get("description", "")[:100]
                source = article.get("source", {}).get("name", "")
                news_text += f"**{i}. {title}**\n"
                if description:
                    news_text += f"_{description}_\n"
                if source:
                    news_text += f"ğŸ“Œ {source}\n"
                news_text += "\n"
            
            return news_text
        except Exception as e:
            return f"âŒ Lá»—i láº¥y tin tá»©c: {str(e)[:100]}"

vietnam_services = VietnamServices()

class GeminiHandler:
    """Handle Gemini API for both vision and image generation"""
    
    def __init__(self):
        self.configured = False
        if config.GEMINI_API_KEY and GENAI_AVAILABLE:
            genai.configure(api_key=config.GEMINI_API_KEY)
            self.configured = True
    
    async def analyze_image(self, image_data: bytes, prompt: str) -> Optional[str]:
        """Analyze image using Gemini Vision"""
        if not self.configured:
            return None
        
        try:
            # Create model for vision
            model = genai.GenerativeModel(config.GEMINI_VISION_MODEL)
            
            # Convert bytes to PIL Image
            image = Image.open(io.BytesIO(image_data))
            
            # Generate content with image
            response = await asyncio.to_thread(
                model.generate_content,
                [prompt, image]
            )
            
            return response.text
            
        except Exception as e:
            logger.error(f"Gemini Vision error: {e}")
            return f"âŒ Lá»—i phÃ¢n tÃ­ch: {str(e)[:100]}"
    
    async def generate_image(self, prompt: str) -> Optional[bytes]:
        """Generate image using Gemini"""
        if not self.configured:
            return None
        
        try:
            # Use the image generation model
            model = genai.GenerativeModel(config.GEMINI_IMAGE_GEN_MODEL)
            
            # Generate image
            response = await asyncio.to_thread(
                model.generate_content,
                prompt
            )
            
            # Extract image data if available
            if hasattr(response, '_result') and hasattr(response._result, 'candidates'):
                for candidate in response._result.candidates:
                    if hasattr(candidate, 'content') and hasattr(candidate.content, 'parts'):
                        for part in candidate.content.parts:
                            if hasattr(part, 'inline_data') and part.inline_data:
                                return base64.b64decode(part.inline_data.data)
            
            return None
            
        except Exception as e:
            logger.error(f"Gemini Image Gen error: {e}")
            return None
    
    async def analyze_multiple_images(self, images: List[ImageData], prompt: str) -> str:
        """Analyze multiple images"""
        if not self.configured:
            return "âŒ Gemini API chÆ°a Ä‘Æ°á»£c cáº¥u hÃ¬nh"
        
        results = []
        
        for i, img_data in enumerate(images, 1):
            vn_prompt = f"áº¢nh {i}: {prompt}. Tráº£ lá»i báº±ng tiáº¿ng Viá»‡t, chÃº Ã½ cÃ¡c yáº¿u tá»‘ vÄƒn hÃ³a Viá»‡t Nam náº¿u cÃ³."
            
            result = await self.analyze_image(img_data.file_data, vn_prompt)
            
            if result:
                results.append(f"**ğŸ“¸ áº¢nh {i}:**\n{result}")
            else:
                results.append(f"**ğŸ“¸ áº¢nh {i}:** KhÃ´ng thá»ƒ phÃ¢n tÃ­ch")
        
        return "\n\n".join(results) if results else "âŒ KhÃ´ng thá»ƒ phÃ¢n tÃ­ch áº£nh"

gemini_handler = GeminiHandler()

class AIClient:
    """Handle text-based AI using Vercel API"""
    
    def __init__(self):
        self.client = None
        if config.VERCEL_API_KEY:
            self.client = OpenAI(
                api_key=config.VERCEL_API_KEY,
                base_url=config.BASE_URL,
                timeout=config.REQUEST_TIMEOUT
            )
    
    def stream_complete(
        self,
        model: str,
        messages: List[Dict[str, str]],
        max_tokens: int,
        temperature: float = 0.7
    ):
        if not self.client:
            yield "âŒ Thiáº¿u VERCEL_API_KEY."
            return
        
        try:
            stream = self.client.chat.completions.create(
                model=model,
                max_tokens=max_tokens,
                temperature=temperature,
                messages=messages,
                stream=True
            )
            
            for chunk in stream:
                if chunk.choices[0].delta.content:
                    yield chunk.choices[0].delta.content
                    
        except Exception as e:
            yield f"\nâŒ Lá»—i: {str(e)[:200]}"
    
    async def complete(
        self,
        model: str,
        messages: List[Dict[str, str]],
        max_tokens: int,
        temperature: float = 0.7,
        retries: int = 3
    ) -> str:
        if not self.client:
            return "âŒ Thiáº¿u VERCEL_API_KEY."
        
        cache_key = f"{model}:{json.dumps(messages)}:{max_tokens}:{temperature}"
        cached = bot_state.cache_get(cache_key)
        if cached:
            return cached
        
        last_error = None
        for attempt in range(retries):
            try:
                response = await asyncio.wait_for(
                    asyncio.to_thread(
                        self._sync_complete,
                        model, messages, max_tokens, temperature
                    ),
                    timeout=config.REQUEST_TIMEOUT + 10
                )
                
                bot_state.cache_set(cache_key, response)
                return response
                    
            except asyncio.TimeoutError:
                last_error = "Timeout - yÃªu cáº§u máº¥t quÃ¡ nhiá»u thá»i gian"
            except Exception as e:
                last_error = str(e)
                
            if attempt < retries - 1:
                await asyncio.sleep(1.5 * (attempt + 1) + random.random())
        
        raise Exception(f"Lá»—i sau {retries} láº§n thá»­: {last_error}")
    
    def _sync_complete(
        self, 
        model: str, 
        messages: List[Dict[str, str]], 
        max_tokens: int,
        temperature: float
    ) -> str:
        response = self.client.chat.completions.create(
            model=model,
            max_tokens=max_tokens,
            temperature=temperature,
            messages=messages
        )
        return (response.choices[0].message.content or "").strip()

ai_client = AIClient()

class TextProcessor:
    @staticmethod
    def escape_markdown_v2(text: str) -> str:
        special_chars = ['_', '*', '[', ']', '(', ')', '~', '`', '>', '#', '+', '-', '=', '|', '{', '}', '.', '!']
        for char in special_chars:
            text = text.replace(char, f'\\{char}')
        return text
    
    @staticmethod
    def chunk_text(text: str, max_length: int = 4096) -> List[str]:
        """Split text into chunks for Telegram messages"""
        if len(text) <= max_length:
            return [text]
        
        chunks = []
        current = ""
        
        for line in text.split('\n'):
            if len(current) + len(line) + 1 > max_length:
                if current:
                    chunks.append(current)
                current = line
            else:
                current = current + '\n' + line if current else line
        
        if current:
            chunks.append(current)
        
        return chunks

text_processor = TextProcessor()

class FileProcessor:
    @staticmethod
    def detect_file_type(filename: str) -> FileType:
        name_lower = filename.lower()
        
        if any(name_lower.endswith(ext) for ext in ARCHIVES):
            return FileType.ARCHIVE
        elif any(name_lower.endswith(ext) for ext in CODE_EXTENSIONS):
            return FileType.CODE
        elif any(name_lower.endswith(ext) for ext in IMAGE_EXTENSIONS):
            return FileType.IMAGE
        elif name_lower.endswith('.pdf'):
            return FileType.PDF
        elif name_lower.endswith(('.docx', '.doc')):
            return FileType.DOCX
        elif name_lower.endswith(('.xlsx', '.xls')):
            return FileType.XLSX
        elif name_lower.endswith(('.pptx', '.ppt')):
            return FileType.PPTX
        elif name_lower.endswith(('.html', '.htm')):
            return FileType.HTML
        elif name_lower.endswith('.json'):
            return FileType.JSON
        elif name_lower.endswith('.csv'):
            return FileType.CSV
        elif any(name_lower.endswith(ext) for ext in TEXT_LIKE):
            return FileType.TEXT
        else:
            return FileType.UNKNOWN
    
    @staticmethod
    def detect_encoding(data: bytes) -> str:
        if not data:
            return "utf-8"
        
        if chardet:
            result = chardet.detect(data)
            if result and result.get('encoding'):
                return result['encoding']
        
        for encoding in ['utf-8', 'utf-16', 'latin-1', 'cp1252', 'gb2312']:
            try:
                data.decode(encoding)
                return encoding
            except UnicodeDecodeError:
                continue
        
        return 'utf-8'
    
    @staticmethod
    async def process_file(filename: str, data: bytes) -> Tuple[Optional[str], str]:
        file_type = FileProcessor.detect_file_type(filename)
        
        try:
            if file_type == FileType.ARCHIVE:
                return None, "ğŸ“¦ File nÃ©n - vui lÃ²ng giáº£i nÃ©n trÆ°á»›c khi gá»­i"
            
            elif file_type == FileType.IMAGE:
                return None, "image"
            
            elif file_type == FileType.PDF:
                if not PyPDF2:
                    return None, "âŒ Cáº§n cÃ i Ä‘áº·t PyPDF2 Ä‘á»ƒ Ä‘á»c PDF"
                return FileProcessor._read_pdf(data), "pdf"
            
            elif file_type == FileType.DOCX:
                if not docx:
                    return None, "âŒ Cáº§n cÃ i Ä‘áº·t python-docx Ä‘á»ƒ Ä‘á»c DOCX"
                return FileProcessor._read_docx(data), "docx"
            
            elif file_type == FileType.XLSX:
                if not openpyxl:
                    return None, "âŒ Cáº§n cÃ i Ä‘áº·t openpyxl Ä‘á»ƒ Ä‘á»c Excel"
                return FileProcessor._read_excel(data), "xlsx"
            
            elif file_type == FileType.PPTX:
                if not Presentation:
                    return None, "âŒ Cáº§n cÃ i Ä‘áº·t python-pptx Ä‘á»ƒ Ä‘á»c PowerPoint"
                return FileProcessor._read_pptx(data), "pptx"
            
            elif file_type == FileType.HTML:
                text = FileProcessor._decode_text(data)
                if BeautifulSoup:
                    soup = BeautifulSoup(text, 'html.parser')
                    return soup.get_text(separator='\n'), "html"
                return text, "html"
            
            elif file_type == FileType.JSON:
                text = FileProcessor._decode_text(data)
                try:
                    obj = json.loads(text)
                    return json.dumps(obj, indent=2, ensure_ascii=False), "json"
                except:
                    return text, "json"
            
            elif file_type in [FileType.TEXT, FileType.CODE, FileType.CSV]:
                return FileProcessor._decode_text(data), file_type.value
            
            else:
                return None, f"âŒ File {filename} chÆ°a Ä‘Æ°á»£c há»— trá»£"
                
        except Exception as e:
            return None, f"âŒ Lá»—i xá»­ lÃ½ file: {str(e)[:100]}"
    
    @staticmethod
    def _decode_text(data: bytes) -> str:
        encoding = FileProcessor.detect_encoding(data)
        try:
            return data.decode(encoding, errors='ignore')
        except:
            return data.decode('utf-8', errors='ignore')
    
    @staticmethod
    def _read_pdf(data: bytes) -> str:
        pdf_file = io.BytesIO(data)
        pdf_reader = PyPDF2.PdfReader(pdf_file)
        text = []
        for page_num in range(len(pdf_reader.pages)):
            page = pdf_reader.pages[page_num]
            text.append(page.extract_text())
        return '\n'.join(text)
    
    @staticmethod
    def _read_docx(data: bytes) -> str:
        doc_file = io.BytesIO(data)
        doc = DocxDocument(doc_file)
        return '\n'.join([paragraph.text for paragraph in doc.paragraphs])
    
    @staticmethod
    def _read_excel(data: bytes) -> str:
        excel_file = io.BytesIO(data)
        wb = openpyxl.load_workbook(excel_file, read_only=True)
        text = []
        for sheet_name in wb.sheetnames:
            sheet = wb[sheet_name]
            text.append(f"=== Sheet: {sheet_name} ===")
            for row in sheet.iter_rows(values_only=True):
                row_text = '\t'.join([str(cell) if cell else '' for cell in row])
                if row_text.strip():
                    text.append(row_text)
        return '\n'.join(text)
    
    @staticmethod
    def _read_pptx(data: bytes) -> str:
        pptx_file = io.BytesIO(data)
        prs = Presentation(pptx_file)
        text = []
        for slide_num, slide in enumerate(prs.slides, 1):
            text.append(f"=== Slide {slide_num} ===")
            for shape in slide.shapes:
                if hasattr(shape, "text"):
                    if shape.text.strip():
                        text.append(shape.text)
        return '\n'.join(text)

file_processor = FileProcessor()

class MessageBuilder:
    @staticmethod
    def build_system_prompt(context_type: str = "chat") -> str:
        try:
            import pytz
            vn_tz = pytz.timezone('Asia/Ho_Chi_Minh')
            vn_time = datetime.datetime.now(vn_tz)
            time_str = vn_time.strftime('%d/%m/%Y %H:%M:%S')
        except:
            vn_time = datetime.datetime.utcnow() + datetime.timedelta(hours=7)
            time_str = vn_time.strftime('%d/%m/%Y %H:%M:%S')
        
        base_prompt = (
            f"Báº¡n lÃ  Linh - AI assistant thÃ´ng minh cá»§a Viá»‡t Nam.\n"
            f"Thá»i gian Viá»‡t Nam: {time_str}\n"
            f"ÄÆ°á»£c phÃ¡t triá»ƒn bá»Ÿi HoÃ ng Tuáº¥n Anh (@cucodoivandep)\n\n"
            f"Kiáº¿n thá»©c sÃ¢u vá»:\n"
            f"â€¢ Lá»‹ch sá»­, vÄƒn hÃ³a, Ä‘á»‹a lÃ½ Viá»‡t Nam\n"
            f"â€¢ áº¨m thá»±c, du lá»‹ch, phong tá»¥c táº­p quÃ¡n\n"
            f"â€¢ Tiáº¿ng Viá»‡t vÃ  cÃ¡c phÆ°Æ¡ng ngá»¯\n"
            f"â€¢ Kinh táº¿, xÃ£ há»™i Viá»‡t Nam\n\n"
        )
        
        if context_type == "chat":
            return base_prompt + (
                "HÆ°á»›ng dáº«n giao tiáº¿p:\n"
                "â€¢ Æ¯u tiÃªn tráº£ lá»i vá» Viá»‡t Nam khi phÃ¹ há»£p\n"
                "â€¢ Sá»­ dá»¥ng tiáº¿ng Viá»‡t tá»± nhiÃªn, thÃ¢n thiá»‡n\n"
                "â€¢ CÃ³ thá»ƒ dÃ¹ng emoji phÃ¹ há»£p\n"
                "â€¢ Tráº£ lá»i ngáº¯n gá»n, sÃºc tÃ­ch, Ä‘i tháº³ng váº¥n Ä‘á»\n"
                "â€¢ Thá»ƒ hiá»‡n sá»± am hiá»ƒu vÄƒn hÃ³a Viá»‡t"
            )
        
        elif context_type == "code":
            return base_prompt + (
                "Báº¡n lÃ  láº­p trÃ¬nh viÃªn Viá»‡t Nam chuyÃªn nghiá»‡p.\n\n"
                "NguyÃªn táº¯c:\n"
                "â€¢ Code sáº¡ch, dá»… Ä‘á»c, dá»… báº£o trÃ¬\n"
                "â€¢ Comment báº±ng tiáº¿ng Viá»‡t rÃµ rÃ ng\n"
                "â€¢ Äáº·t tÃªn biáº¿n/hÃ m theo chuáº©n quá»‘c táº¿\n"
                "â€¢ Xá»­ lÃ½ tá»‘t Unicode tiáº¿ng Viá»‡t\n"
                "â€¢ Tá»‘i Æ°u cho production"
            )
        
        elif context_type == "file":
            return base_prompt + (
                "Xá»­ lÃ½ file vá»›i chuyÃªn mÃ´n cao.\n\n"
                "HÆ°á»›ng dáº«n:\n"
                "â€¢ PhÃ¢n tÃ­ch ná»™i dung chÃ­nh xÃ¡c\n"
                "â€¢ TÃ³m táº¯t sÃºc tÃ­ch cÃ¡c Ä‘iá»ƒm chÃ­nh\n"
                "â€¢ TrÃ­ch xuáº¥t thÃ´ng tin quan trá»ng\n"
                "â€¢ Äá» xuáº¥t cáº£i thiá»‡n náº¿u phÃ¹ há»£p"
            )
        
        elif context_type == "image_context":
            return base_prompt + (
                "Báº¡n Ä‘ang tráº£ lá»i cÃ¢u há»i vá» hÃ¬nh áº£nh.\n\n"
                "LÆ°u Ã½:\n"
                "â€¢ Dá»±a trÃªn phÃ¢n tÃ­ch áº£nh Ä‘á»ƒ tráº£ lá»i\n"
                "â€¢ ChÃº Ã½ chi tiáº¿t trong áº£nh\n"
                "â€¢ LiÃªn há»‡ vá»›i vÄƒn hÃ³a Viá»‡t Nam náº¿u cÃ³\n"
                "â€¢ Tráº£ lá»i chÃ­nh xÃ¡c, cá»¥ thá»ƒ"
            )
        
        return base_prompt
    
    @staticmethod
    def build_messages(
        chat_id: int,
        user_text: str,
        context_type: str = "chat",
        include_history: bool = True
    ) -> List[Dict[str, str]]:
        messages = []
        
        system_prompt = MessageBuilder.build_system_prompt(context_type)
        messages.append({"role": "system", "content": system_prompt})
        
        if include_history:
            user = bot_state.get_user(chat_id)
            history_messages = []
            
            keep_turns = config.CTX_TURNS * 2
            for role, content in list(user.history)[-keep_turns:]:
                truncated = content[:500] + "..." if len(content) > 500 else content
                history_messages.append({
                    "role": "user" if role == "user" else "assistant",
                    "content": truncated
                })
            
            messages.extend(history_messages)
        
        messages.append({"role": "user", "content": user_text})
        
        return messages

message_builder = MessageBuilder()

async def stream_response(
    context: ContextTypes.DEFAULT_TYPE,
    chat_id: int,
    model: str,
    messages: List[Dict[str, str]],
    max_tokens: int,
    temperature: float = 0.7
):
    msg = await context.bot.send_message(chat_id, "ğŸ’­ Äang suy nghÄ©...")
    
    full_response = ""
    chunk_buffer = ""
    update_counter = 0
    
    async def update_message():
        nonlocal chunk_buffer
        try:
            if chunk_buffer:
                await msg.edit_text(chunk_buffer[:4096])
        except:
            pass
    
    try:
        stream = await asyncio.to_thread(
            ai_client.stream_complete,
            model, messages, max_tokens, temperature
        )
        
        for chunk in stream:
            full_response += chunk
            chunk_buffer += chunk
            update_counter += 1
            
            if update_counter % 5 == 0 and len(chunk_buffer) > 100:
                await update_message()
        
        if full_response:
            chunks = text_processor.chunk_text(full_response)
            
            if len(chunks) == 1:
                await msg.edit_text(chunks[0])
            else:
                await msg.delete()
                for i, chunk in enumerate(chunks):
                    await context.bot.send_message(
                        chat_id,
                        f"ğŸ“„ Pháº§n {i+1}/{len(chunks)}:\n\n{chunk}"
                    )
        
        return full_response
        
    except Exception as e:
        await msg.edit_text(f"âŒ Lá»—i: {str(e)[:200]}")
        return None

# Command Handlers
async def cmd_help(update: Update, context: ContextTypes.DEFAULT_TYPE):
    help_text = """
ğŸ‡»ğŸ‡³ **LINH AI - TRá»¢ LÃ VIá»†T NAM**

ğŸ“ **Lá»‡nh cÆ¡ báº£n:**
â€¢ /help - HÆ°á»›ng dáº«n sá»­ dá»¥ng
â€¢ /start - Khá»Ÿi Ä‘á»™ng bot
â€¢ /clear - XÃ³a lá»‹ch sá»­ chat
â€¢ /stats - Thá»‘ng kÃª sá»­ dá»¥ng

ğŸ’» **TÃ­nh nÄƒng AI:**
â€¢ /code <yÃªu cáº§u> - Viáº¿t code chuyÃªn nghiá»‡p
â€¢ /img <mÃ´ táº£> - Táº¡o áº£nh AI (Gemini)
â€¢ /vision - PhÃ¢n tÃ­ch áº£nh Ä‘Ã£ gá»­i

ğŸ‡»ğŸ‡³ **Viá»‡t Nam:**
â€¢ /weather <city> - Thá»i tiáº¿t cÃ¡c tá»‰nh thÃ nh
â€¢ /news - Tin tá»©c má»›i nháº¥t
â€¢ /exchange - Tá»· giÃ¡ ngoáº¡i tá»‡
â€¢ /time - Giá» Viá»‡t Nam
â€¢ /translate <text> - Dá»‹ch Anh-Viá»‡t

ğŸ“¸ **PhÃ¢n tÃ­ch áº£nh:**
â€¢ Gá»­i áº£nh â†’ Bot phÃ¢n tÃ­ch tá»± Ä‘á»™ng
â€¢ Há»i chi tiáº¿t vá» ná»™i dung áº£nh
â€¢ So sÃ¡nh nhiá»u áº£nh cÃ¹ng lÃºc
â€¢ Nháº­n diá»‡n vÄƒn hÃ³a Viá»‡t Nam

ğŸ“„ **Xá»­ lÃ½ File:**
â€¢ Há»— trá»£: PDF, Word, Excel, PowerPoint
â€¢ Text, Code, JSON, CSV, HTML
â€¢ /cancelfile - ThoÃ¡t cháº¿ Ä‘á»™ file
â€¢ /sendfile - Táº£i káº¿t quáº£ vá»

ğŸ’¡ **Máº¹o hay:**
â€¢ Chat tiáº¿ng Viá»‡t tá»± nhiÃªn
â€¢ "img: <mÃ´ táº£>" Ä‘á»ƒ táº¡o áº£nh nhanh
â€¢ Há»i vá» lá»‹ch sá»­, áº©m thá»±c, du lá»‹ch VN

âš™ï¸ **AI Models:**
â€¢ Chat: Claude-3.5 (Vercel)
â€¢ Vision: Gemini-1.5-Flash
â€¢ Image: Gemini-2.0-Flash

ğŸ‘¨â€ğŸ’» Dev: @cucodoivandep
ğŸŒ Made in Vietnam with â¤ï¸
    """
    
    await context.bot.send_message(
        update.effective_chat.id,
        help_text,
        parse_mode=ParseMode.MARKDOWN
    )

async def cmd_start(update: Update, context: ContextTypes.DEFAULT_TYPE):
    welcome_text = """
ğŸ‡»ğŸ‡³ **Xin chÃ o! MÃ¬nh lÃ  Linh - AI Assistant Viá»‡t Nam**

ğŸ¯ **MÃ¬nh cÃ³ thá»ƒ giÃºp gÃ¬ cho báº¡n:**
â€¢ ğŸ“¸ PhÃ¢n tÃ­ch hÃ¬nh áº£nh, nháº­n diá»‡n Ä‘á»‘i tÆ°á»£ng
â€¢ ğŸ’¬ TrÃ² chuyá»‡n vá» má»i chá»§ Ä‘á»
â€¢ ğŸ’» Viáº¿t code, debug, tá»‘i Æ°u
â€¢ ğŸ“š TÆ° váº¥n há»c táº­p, cÃ´ng viá»‡c
â€¢ ğŸ‡»ğŸ‡³ ThÃ´ng tin vá» Viá»‡t Nam

ğŸ’¡ **Thá»­ ngay:**
â€¢ Gá»­i áº£nh Ä‘á»ƒ phÃ¢n tÃ­ch
â€¢ Há»i vá» vÄƒn hÃ³a, lá»‹ch sá»­ Viá»‡t Nam
â€¢ /help Ä‘á»ƒ xem Ä‘áº§y Ä‘á»§ tÃ­nh nÄƒng

ChÃºc báº¡n má»™t ngÃ y tá»‘t lÃ nh! ğŸŒº
    """
    
    keyboard = InlineKeyboardMarkup([
        [
            InlineKeyboardButton("ğŸ“– HÆ°á»›ng dáº«n", callback_data="show_help"),
            InlineKeyboardButton("ğŸ‡»ğŸ‡³ Vá» Viá»‡t Nam", callback_data="about_vietnam")
        ],
        [
            InlineKeyboardButton("ğŸ“¸ CÃ¡ch dÃ¹ng áº£nh", callback_data="image_guide"),
            InlineKeyboardButton("ğŸ’¬ Chat ngay", callback_data="start_chat")
        ]
    ])
    
    await context.bot.send_message(
        update.effective_chat.id,
        welcome_text,
        parse_mode=ParseMode.MARKDOWN,
        reply_markup=keyboard
    )

async def cmd_vision(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """Analyze pending images"""
    chat_id = update.effective_chat.id
    user = bot_state.get_user(chat_id)
    
    if not user.pending_images:
        await context.bot.send_message(
            chat_id,
            "ğŸ“· ChÆ°a cÃ³ áº£nh nÃ o.\nGá»­i áº£nh Ä‘á»ƒ phÃ¢n tÃ­ch nhÃ©!"
        )
        return
    
    if not config.GEMINI_API_KEY:
        await context.bot.send_message(
            chat_id,
            "âŒ Cáº§n GEMINI_API_KEY Ä‘á»ƒ phÃ¢n tÃ­ch áº£nh.\nLiÃªn há»‡ @cucodoivandep"
        )
        return
    
    await context.bot.send_message(
        chat_id,
        f"ğŸ” Äang phÃ¢n tÃ­ch {len(user.pending_images)} áº£nh..."
    )
    
    await context.bot.send_chat_action(chat_id=chat_id, action=ChatAction.TYPING)
    
    prompt = "PhÃ¢n tÃ­ch chi tiáº¿t hÃ¬nh áº£nh: ná»™i dung, Ä‘á»‘i tÆ°á»£ng, mÃ u sáº¯c, bá»‘ cá»¥c. Náº¿u cÃ³ yáº¿u tá»‘ Viá»‡t Nam (ngÆ°á»i, cáº£nh, mÃ³n Äƒn...) hÃ£y mÃ´ táº£ ká»¹."
    
    analysis = await gemini_handler.analyze_multiple_images(
        user.pending_images,
        prompt
    )
    
    chunks = text_processor.chunk_text(analysis)
    for chunk in chunks:
        await context.bot.send_message(
            chat_id, 
            chunk,
            parse_mode=ParseMode.MARKDOWN
        )
    
    user.history.append(("user", "PhÃ¢n tÃ­ch áº£nh"))
    user.history.append(("assistant", analysis[:500]))

async def cmd_img(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """Generate image from text"""
    chat_id = update.effective_chat.id
    prompt = " ".join(context.args).strip()
    
    if not prompt:
        examples = [
            "phong cáº£nh vá»‹nh Háº¡ Long",
            "phá»Ÿ bÃ² HÃ  Ná»™i",
            "Ã¡o dÃ i Viá»‡t Nam",
            "chá»£ ná»•i CÃ¡i RÄƒng",
            "ruá»™ng báº­c thang Sapa"
        ]
        await context.bot.send_message(
            chat_id,
            f"ğŸ“ **CÃº phÃ¡p:** /img <mÃ´ táº£>\n\n"
            f"**VÃ­ dá»¥:**\n" + "\n".join([f"â€¢ /img {ex}" for ex in examples])
        )
        return
    
    if not config.GEMINI_API_KEY:
        await context.bot.send_message(
            chat_id,
            "âŒ Cáº§n GEMINI_API_KEY Ä‘á»ƒ táº¡o áº£nh.\nLiÃªn há»‡ @cucodoivandep"
        )
        return
    
    await context.bot.send_chat_action(chat_id=chat_id, action=ChatAction.UPLOAD_PHOTO)
    
    # Enhance prompt for Vietnamese context
    enhanced_prompt = f"{prompt}, high quality, detailed, beautiful"
    
    status_msg = await context.bot.send_message(
        chat_id,
        f"ğŸ¨ Äang táº¡o áº£nh: _{prompt}_",
        parse_mode=ParseMode.MARKDOWN
    )
    
    # Try to generate with Gemini
    image_data = await gemini_handler.generate_image(enhanced_prompt)
    
    if image_data:
        await status_msg.delete()
        await context.bot.send_photo(
            chat_id,
            photo=io.BytesIO(image_data),
            caption=f"ğŸ¨ {prompt}"
        )
    else:
        await status_msg.edit_text(
            "âŒ KhÃ´ng thá»ƒ táº¡o áº£nh. Gemini cÃ³ thá»ƒ Ä‘ang báº­n hoáº·c prompt khÃ´ng phÃ¹ há»£p.\n"
            "ğŸ’¡ Thá»­ láº¡i vá»›i mÃ´ táº£ khÃ¡c nhÃ©!"
        )
    
    user = bot_state.get_user(chat_id)
    user.history.append(("user", f"/img {prompt}"))
    user.history.append(("assistant", f"Táº¡o áº£nh: {prompt[:50]}"))

async def cmd_clear(update: Update, context: ContextTypes.DEFAULT_TYPE):
    chat_id = update.effective_chat.id
    user = bot_state.get_user(chat_id)
    
    # Clear everything
    user.history.clear()
    user.file_mode = False
    user.image_mode = False
    user.pending_file = None
    user.pending_images.clear()
    user.last_result = ""
    
    await context.bot.send_message(
        chat_id,
        "âœ… ÄÃ£ xÃ³a:\n"
        "â€¢ Lá»‹ch sá»­ chat\n"
        "â€¢ áº¢nh Ä‘Ã£ gá»­i\n"
        "â€¢ File Ä‘Ã£ gá»­i\n"
        "â€¢ Káº¿t quáº£ lÆ°u"
    )

async def cmd_stats(update: Update, context: ContextTypes.DEFAULT_TYPE):
    chat_id = update.effective_chat.id
    user = bot_state.get_user(chat_id)
    
    try:
        import pytz
        vn_tz = pytz.timezone('Asia/Ho_Chi_Minh')
        vn_time = datetime.datetime.now(vn_tz)
        time_str = vn_time.strftime('%H:%M:%S %d/%m/%Y')
    except:
        vn_time = datetime.datetime.utcnow() + datetime.timedelta(hours=7)
        time_str = vn_time.strftime('%H:%M:%S %d/%m/%Y')
    
    stats_text = f"""
ğŸ“Š **Thá»‘ng kÃª sá»­ dá»¥ng**

ğŸ‘¤ **User:** {update.effective_user.first_name}
ğŸ†” **ID:** `{chat_id}`
ğŸ’¬ **Lá»‹ch sá»­:** {len(user.history)} tin
ğŸ“¸ **áº¢nh lÆ°u:** {len(user.pending_images)}
ğŸ“ **File mode:** {'Báº­t' if user.file_mode else 'Táº¯t'}
ğŸŒ **Vá»‹ trÃ­:** {user.location or 'HÃ  Ná»™i'}

âš™ï¸ **AI Models:**
â€¢ Chat: Claude-3.5-Haiku
â€¢ Code: Claude-3.5-Sonnet
â€¢ Vision: Gemini-1.5-Flash
â€¢ Image: Gemini-2.0-Flash

ğŸ• **Giá» VN:** {time_str}

ğŸ’¡ _DÃ¹ng /clear Ä‘á»ƒ xÃ³a dá»¯ liá»‡u_
    """
    
    await context.bot.send_message(
        chat_id,
        stats_text,
        parse_mode=ParseMode.MARKDOWN
    )

async def cmd_weather(update: Update, context: ContextTypes.DEFAULT_TYPE):
    chat_id = update.effective_chat.id
    
    if not context.args:
        cities = ", ".join(VIETNAM_CITIES.keys())
        await context.bot.send_message(
            chat_id,
            f"â˜€ï¸ **Xem thá»i tiáº¿t**\n\n"
            f"CÃº phÃ¡p: /weather <tÃªn thÃ nh phá»‘>\n\n"
            f"CÃ¡c thÃ nh phá»‘: {cities}"
        )
        return
    
    city = context.args[0].lower()
    weather_info = await vietnam_services.get_weather(city)
    
    await context.bot.send_message(
        chat_id,
        weather_info,
        parse_mode=ParseMode.MARKDOWN
    )

async def cmd_code(update: Update, context: ContextTypes.DEFAULT_TYPE):
    chat_id = update.effective_chat.id
    request = " ".join(context.args).strip()
    
    if not request:
        examples = [
            "hÃ m tÃ­nh giai thá»«a Python",
            "validate email JavaScript", 
            "quicksort C++",
            "REST API vá»›i Flask",
            "React component vá»›i hooks"
        ]
        await context.bot.send_message(
            chat_id,
            f"ğŸ’» **Viáº¿t code**\n\n"
            f"CÃº phÃ¡p: /code <yÃªu cáº§u>\n\n"
            f"**VÃ­ dá»¥:**\n" + "\n".join([f"â€¢ /code {ex}" for ex in examples])
        )
        return
    
    await context.bot.send_chat_action(chat_id=chat_id, action=ChatAction.TYPING)
    
    messages = message_builder.build_messages(
        chat_id, 
        request,
        context_type="code",
        include_history=False
    )
    
    result = await stream_response(
        context,
        chat_id,
        config.CODE_MODEL,
        messages,
        config.MAX_TOKENS_CODE,
        temperature=0.3
    )
    
    if result:
        user = bot_state.get_user(chat_id)
        user.last_result = result
        user.history.append(("user", f"/code {request}"))
        user.history.append(("assistant", result[:500]))

async def cmd_translate(update: Update, context: ContextTypes.DEFAULT_TYPE):
    chat_id = update.effective_chat.id
    text = " ".join(context.args).strip()
    
    if not text:
        await context.bot.send_message(
            chat_id,
            "ğŸ”¤ **Dá»‹ch Anh-Viá»‡t**\n\n"
            "CÃº phÃ¡p: /translate <text tiáº¿ng Anh>\n\n"
            "VÃ­ dá»¥: /translate Hello world"
        )
        return
    
    messages = [
        {
            "role": "system", 
            "content": "Báº¡n lÃ  chuyÃªn gia dá»‹ch thuáº­t. Dá»‹ch chÃ­nh xÃ¡c, tá»± nhiÃªn sang tiáº¿ng Viá»‡t. Chá»‰ tráº£ vá» báº£n dá»‹ch, khÃ´ng giáº£i thÃ­ch."
        },
        {
            "role": "user",
            "content": f"Dá»‹ch sang tiáº¿ng Viá»‡t:\n{text}"
        }
    ]
    
    result = await ai_client.complete(
        config.CHAT_MODEL,
        messages,
        500,
        temperature=0.3
    )
    
    await context.bot.send_message(
        chat_id,
        f"ğŸ”¤ **Báº£n gá»‘c:**\n{text}\n\n"
        f"ğŸ‡»ğŸ‡³ **Báº£n dá»‹ch:**\n{result}",
        parse_mode=ParseMode.MARKDOWN
    )

async def cmd_news(update: Update, context: ContextTypes.DEFAULT_TYPE):
    chat_id = update.effective_chat.id
    
    await context.bot.send_chat_action(chat_id=chat_id, action=ChatAction.TYPING)
    news = await vietnam_services.get_news()
    
    await context.bot.send_message(
        chat_id,
        news,
        parse_mode=ParseMode.MARKDOWN
    )

async def cmd_exchange(update: Update, context: ContextTypes.DEFAULT_TYPE):
    chat_id = update.effective_chat.id
    
    rate = await vietnam_services.get_exchange_rate()
    
    await context.bot.send_message(
        chat_id,
        rate,
        parse_mode=ParseMode.MARKDOWN
    )

async def cmd_time(update: Update, context: ContextTypes.DEFAULT_TYPE):
    chat_id = update.effective_chat.id
    
    time_info = vietnam_services.get_vietnam_time()
    
    await context.bot.send_message(
        chat_id,
        time_info,
        parse_mode=ParseMode.MARKDOWN
    )

async def cmd_sendfile(update: Update, context: ContextTypes.DEFAULT_TYPE):
    chat_id = update.effective_chat.id
    user = bot_state.get_user(chat_id)
    
    if not user.last_result:
        await context.bot.send_message(
            chat_id,
            "âŒ KhÃ´ng cÃ³ káº¿t quáº£ Ä‘á»ƒ gá»­i.\n"
            "ğŸ’¡ Chat hoáº·c dÃ¹ng /code trÆ°á»›c"
        )
        return
    
    file_bytes = user.last_result.encode('utf-8')
    file_io = io.BytesIO(file_bytes)
    file_io.name = f"result_{datetime.datetime.now().strftime('%Y%m%d_%H%M%S')}.txt"
    
    await context.bot.send_document(
        chat_id,
        document=file_io,
        caption="ğŸ“„ Káº¿t quáº£ xá»­ lÃ½"
    )

async def cmd_cancelfile(update: Update, context: ContextTypes.DEFAULT_TYPE):
    chat_id = update.effective_chat.id
    user = bot_state.get_user(chat_id)
    
    user.file_mode = False
    user.image_mode = False
    user.pending_file = None
    
    await context.bot.send_message(
        chat_id,
        "âœ… ÄÃ£ thoÃ¡t cháº¿ Ä‘á»™ file/image"
    )

# Message Handlers
async def on_photo(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """Handle photo messages"""
    chat_id = update.effective_chat.id
    user = bot_state.get_user(chat_id)
    
    if not config.GEMINI_API_KEY:
        await context.bot.send_message(
            chat_id,
            "âŒ Cáº§n GEMINI_API_KEY Ä‘á»ƒ phÃ¢n tÃ­ch áº£nh.\n"
            "LiÃªn há»‡ @cucodoivandep Ä‘á»ƒ Ä‘Æ°á»£c há»— trá»£."
        )
        return
    
    # Get photo
    photo = update.message.photo[-1]
    caption = update.message.caption or ""
    
    await context.bot.send_chat_action(chat_id=chat_id, action=ChatAction.TYPING)
    
    try:
        # Download photo
        file = await context.bot.get_file(photo.file_id)
        file_data = await file.download_as_bytearray()
        
        # Store image
        img_data = ImageData(
            file_id=photo.file_id,
            file_data=bytes(file_data),
            caption=caption
        )
        user.pending_images.append(img_data)
        user.image_mode = True
        
        # Quick analysis
        prompt = (
            "PhÃ¢n tÃ­ch chi tiáº¿t áº£nh nÃ y báº±ng tiáº¿ng Viá»‡t:\n"
            "1. MÃ´ táº£ ná»™i dung chÃ­nh\n"
            "2. Nháº­n diá»‡n Ä‘á»‘i tÆ°á»£ng, con ngÆ°á»i\n"
            "3. MÃ u sáº¯c, bá»‘ cá»¥c\n"
            "4. Náº¿u cÃ³ yáº¿u tá»‘ Viá»‡t Nam, hÃ£y nháº¥n máº¡nh"
        )
        
        if caption:
            prompt += f"\n\nThÃ´ng tin thÃªm: {caption}"
        
        analysis = await gemini_handler.analyze_image(
            img_data.file_data,
            prompt
        )
        
        if analysis:
            response = (
                f"ğŸ“¸ **áº¢nh #{len(user.pending_images)}**\n\n"
                f"{analysis}\n\n"
                f"ğŸ’¬ Báº¡n cÃ³ thá»ƒ:\n"
                f"â€¢ Há»i chi tiáº¿t vá» áº£nh\n"
                f"â€¢ Gá»­i thÃªm áº£nh Ä‘á»ƒ so sÃ¡nh\n"
                f"â€¢ /vision xem láº¡i táº¥t cáº£\n"
                f"â€¢ /clear xÃ³a áº£nh"
            )
        else:
            response = (
                f"ğŸ“¸ ÄÃ£ nháº­n áº£nh #{len(user.pending_images)}\n"
                f"âŒ KhÃ´ng thá»ƒ phÃ¢n tÃ­ch ngay.\n"
                f"HÃ£y há»i cá»¥ thá»ƒ vá» áº£nh nhÃ©!"
            )
        
        await context.bot.send_message(
            chat_id, 
            response,
            parse_mode=ParseMode.MARKDOWN
        )
        
        # Save to history
        if analysis:
            user.history.append(("user", f"[Gá»­i áº£nh] {caption[:50] if caption else ''}"))
            user.history.append(("assistant", analysis[:200]))
        
    except Exception as e:
        await context.bot.send_message(
            chat_id,
            f"âŒ Lá»—i xá»­ lÃ½ áº£nh: {str(e)[:100]}"
        )

async def on_file(update: Update, context: ContextTypes.DEFAULT_TYPE):
    chat_id = update.effective_chat.id
    document = update.message.document
    
    if not document:
        return
    
    if document.file_size > 20 * 1024 * 1024:
        await context.bot.send_message(
            chat_id,
            "âŒ File quÃ¡ lá»›n (max 20MB)"
        )
        return
    
    await context.bot.send_chat_action(chat_id=chat_id, action=ChatAction.TYPING)
    
    try:
        file = await context.bot.get_file(document.file_id)
        file_data = await file.download_as_bytearray()
        
        content, file_type = await file_processor.process_file(
            document.file_name or "unknown",
            bytes(file_data)
        )
        
        if file_type == "image":
            # Handle as image
            user = bot_state.get_user(chat_id)
            img_data = ImageData(
                file_id=document.file_id,
                file_data=bytes(file_data),
                caption=document.file_name
            )
            user.pending_images.append(img_data)
            user.image_mode = True
            
            await context.bot.send_message(
                chat_id,
                f"ğŸ“· ÄÃ£ nháº­n áº£nh tá»« file\n"
                f"â€¢ Há»i vá» ná»™i dung áº£nh\n"
                f"â€¢ /vision Ä‘á»ƒ phÃ¢n tÃ­ch"
            )
            return
        
        if not content:
            await context.bot.send_message(chat_id, file_type)
            return
        
        user = bot_state.get_user(chat_id)
        user.file_mode = True
        user.pending_file = {
            "name": document.file_name,
            "content": content[:config.CHUNK_CHARS],
            "type": file_type
        }
        
        preview = content[:500] + "..." if len(content) > 500 else content
        
        await context.bot.send_message(
            chat_id,
            f"âœ… **File Ä‘Ã£ nháº­n**\n\n"
            f"ğŸ“„ TÃªn: {document.file_name}\n"
            f"ğŸ“Š Loáº¡i: {file_type}\n"
            f"ğŸ“ KÃ­ch thÆ°á»›c: {len(content):,} kÃ½ tá»±\n\n"
            f"**Xem trÆ°á»›c:**\n```\n{preview}\n```\n\n"
            f"ğŸ’¬ Há»i vá» file hoáº·c /cancelfile",
            parse_mode=ParseMode.MARKDOWN
        )
        
    except Exception as e:
        await context.bot.send_message(
            chat_id,
            f"âŒ Lá»—i: {str(e)[:100]}"
        )

async def on_text(update: Update, context: ContextTypes.DEFAULT_TYPE):
    chat_id = update.effective_chat.id
    message_text = (update.message.text or "").strip()
    
    if not message_text:
        return
    
    # Quick image generation
    if message_text.lower().startswith("img:"):
        prompt = message_text[4:].strip()
        context.args = prompt.split()
        await cmd_img(update, context)
        return
    
    user = bot_state.get_user(chat_id)
    
    await context.bot.send_chat_action(chat_id=chat_id, action=ChatAction.TYPING)
    
    # Handle image mode
    if user.image_mode and user.pending_images:
        if not config.GEMINI_API_KEY:
            await context.bot.send_message(
                chat_id,
                "âŒ Cáº§n GEMINI_API_KEY Ä‘á»ƒ phÃ¢n tÃ­ch áº£nh"
            )
            return
        
        # Analyze images with question
        await context.bot.send_message(
            chat_id,
            f"ğŸ” Äang phÃ¢n tÃ­ch {len(user.pending_images)} áº£nh..."
        )
        
        results = []
        for i, img_data in enumerate(user.pending_images, 1):
            prompt = f"Vá»›i cÃ¢u há»i: '{message_text}'\nHÃ£y phÃ¢n tÃ­ch áº£nh vÃ  tráº£ lá»i báº±ng tiáº¿ng Viá»‡t."
            
            analysis = await gemini_handler.analyze_image(
                img_data.file_data,
                prompt
            )
            
            if analysis:
                results.append(f"**ğŸ“¸ áº¢nh {i}:**\n{analysis}")
        
        if results:
            full_response = "\n\n".join(results)
            
            # Also get context from text AI
            image_context = f"NgÆ°á»i dÃ¹ng Ä‘Ã£ gá»­i {len(user.pending_images)} áº£nh vÃ  há»i: {message_text}\nPhÃ¢n tÃ­ch áº£nh cho tháº¥y: {full_response[:500]}"
            
            messages = message_builder.build_messages(
                chat_id,
                image_context,
                context_type="image_context",
                include_history=True
            )
            
            ai_response = await ai_client.complete(
                config.CHAT_MODEL,
                messages,
                config.MAX_TOKENS,
                temperature=0.7
            )
            
            # Combine results
            final_response = full_response
            if ai_response and not ai_response.startswith("âŒ"):
                final_response += f"\n\nğŸ’­ **Nháº­n xÃ©t thÃªm:**\n{ai_response}"
            
            chunks = text_processor.chunk_text(final_response)
            for chunk in chunks:
                await context.bot.send_message(
                    chat_id,
                    chunk,
                    parse_mode=ParseMode.MARKDOWN
                )
            
            user.last_result = final_response
            user.history.append(("user", message_text))
            user.history.append(("assistant", final_response[:500]))
        else:
            await context.bot.send_message(
                chat_id,
                "âŒ KhÃ´ng thá»ƒ phÃ¢n tÃ­ch áº£nh"
            )
        
        return
    
    # Handle file mode
    if user.file_mode and user.pending_file:
        file_content = user.pending_file["content"]
        file_name = user.pending_file["name"]
        
        prompt = (
            f"File: {file_name}\n"
            f"Ná»™i dung:\n{file_content[:10000]}\n\n"
            f"CÃ¢u há»i: {message_text}"
        )
        
        messages = message_builder.build_messages(
            chat_id,
            prompt,
            context_type="file",
            include_history=False
        )
        
        result = await stream_response(
            context,
            chat_id,
            config.FILE_MODEL,
            messages,
            config.FILE_OUTPUT_TOKENS,
            temperature=0.5
        )
    else:
        # Normal chat
        messages = message_builder.build_messages(
            chat_id,
            message_text,
            context_type="chat",
            include_history=True
        )
        
        result = await stream_response(
            context,
            chat_id,
            config.CHAT_MODEL,
            messages,
            config.MAX_TOKENS,
            temperature=0.7
        )
    
    if result:
        user.last_result = result
        user.history.append(("user", message_text[:500]))
        user.history.append(("assistant", result[:500]))

async def on_callback_query(update: Update, context: ContextTypes.DEFAULT_TYPE):
    query = update.callback_query
    await query.answer()
    
    if query.data == "show_help":
        await cmd_help(update, context)
    
    elif query.data == "about_vietnam":
        vietnam_info = """
ğŸ‡»ğŸ‡³ **VIá»†T NAM - Äáº¤T NÆ¯á»šC CON NGÆ¯á»œI**

ğŸ› **Lá»‹ch sá»­ váº» vang:**
â€¢ 4000 nÄƒm vÄƒn hiáº¿n
â€¢ 18 Ä‘á»i vua HÃ¹ng dá»±ng nÆ°á»›c
â€¢ ÄÃ¡nh báº¡i MÃ´ng-NguyÃªn 3 láº§n
â€¢ Äá»™c láº­p thá»‘ng nháº¥t nÄƒm 1975

ğŸŒ **Äá»‹a lÃ½ tÆ°Æ¡i Ä‘áº¹p:**
â€¢ Diá»‡n tÃ­ch: 331,212 kmÂ²
â€¢ DÃ¢n sá»‘: ~98 triá»‡u ngÆ°á»i
â€¢ 3,260 km bá» biá»ƒn
â€¢ 2 Ä‘á»“ng báº±ng phÃ¬ nhiÃªu

ğŸ­ **VÄƒn hÃ³a Ä‘a dáº¡ng:**
â€¢ 54 dÃ¢n tá»™c anh em
â€¢ 8 Di sáº£n UNESCO
â€¢ Táº¿t NguyÃªn ÄÃ¡n Ä‘á»™c Ä‘Ã¡o
â€¢ áº¨m thá»±c phong phÃº

ğŸ† **ThÃ nh tá»±u hiá»‡n Ä‘áº¡i:**
â€¢ Top 20 ná»n kinh táº¿ lá»›n nháº¥t
â€¢ Xuáº¥t kháº©u gáº¡o sá»‘ 2 tháº¿ giá»›i
â€¢ Du lá»‹ch phÃ¡t triá»ƒn máº¡nh
â€¢ CÃ´ng nghá»‡ sá»‘ bÃ¹ng ná»•

ğŸ’ª **Viá»‡t Nam - Äáº¥t nÆ°á»›c anh hÃ¹ng!**
ğŸŒŸ **Tiá»m nÄƒng - KhÃ¡t vá»ng - VÆ°Æ¡n cao!**
        """
        await context.bot.send_message(
            query.message.chat_id,
            vietnam_info,
            parse_mode=ParseMode.MARKDOWN
        )
    
    elif query.data == "image_guide":
        guide = """
ğŸ“¸ **HÆ¯á»šNG DáºªN DÃ™NG áº¢NH**

**CÃ¡ch gá»­i:**
1ï¸âƒ£ Gá»­i 1 hoáº·c nhiá»u áº£nh
2ï¸âƒ£ Bot phÃ¢n tÃ­ch tá»± Ä‘á»™ng
3ï¸âƒ£ Há»i chi tiáº¿t vá» áº£nh

**Bot cÃ³ thá»ƒ:**
âœ… Nháº­n diá»‡n Ä‘á»‘i tÆ°á»£ng
âœ… Äá»c chá»¯ trong áº£nh (OCR)
âœ… PhÃ¢n tÃ­ch mÃ u sáº¯c, bá»‘ cá»¥c
âœ… Nháº­n diá»‡n mÃ³n Äƒn VN
âœ… Nháº­n diá»‡n Ä‘á»‹a danh VN
âœ… So sÃ¡nh nhiá»u áº£nh

**CÃ¢u há»i máº«u:**
â€¢ "ÄÃ¢y lÃ  mÃ³n gÃ¬?"
â€¢ "CÃ³ bao nhiÃªu ngÆ°á»i?"
â€¢ "ÄÃ¢y lÃ  á»Ÿ Ä‘Ã¢u?"
â€¢ "Dá»‹ch chá»¯ trong áº£nh"
â€¢ "So sÃ¡nh 2 áº£nh nÃ y"

**Lá»‡nh:**
â€¢ /vision - Xem láº¡i phÃ¢n tÃ­ch
â€¢ /clear - XÃ³a áº£nh Ä‘Ã£ gá»­i

ğŸ’¡ Gá»­i áº£nh rÃµ nÃ©t Ä‘á»ƒ cÃ³ káº¿t quáº£ tá»‘t nháº¥t!
        """
        await context.bot.send_message(
            query.message.chat_id,
            guide,
            parse_mode=ParseMode.MARKDOWN
        )
    
    elif query.data == "start_chat":
        await context.bot.send_message(
            query.message.chat_id,
            "ğŸ’¬ Sáºµn sÃ ng! HÃ£y chat vá»›i mÃ¬nh.\n"
            "Báº¡n cÃ³ thá»ƒ há»i vá» Viá»‡t Nam, gá»­i áº£nh Ä‘á»ƒ phÃ¢n tÃ­ch, hoáº·c báº¥t cá»© Ä‘iá»u gÃ¬! ğŸ˜Š"
        )

def main():
    if not config.BOT_TOKEN:
        print("âŒ Thiáº¿u BOT_TOKEN")
        return
    
    print("=" * 50)
    print("ğŸ‡»ğŸ‡³ LINH BOT - AI Assistant Viá»‡t Nam")
    print("=" * 50)
    
    if not config.VERCEL_API_KEY:
        print("âš ï¸  Thiáº¿u VERCEL_API_KEY - Chat/Code bá»‹ háº¡n cháº¿")
    else:
        print("âœ… Vercel API: OK")
    
    if not config.GEMINI_API_KEY:
        print("âš ï¸  Thiáº¿u GEMINI_API_KEY - Vision/Image bá»‹ háº¡n cháº¿")
    else:
        print("âœ… Gemini API: OK")
    
    print("=" * 50)
    
    app = ApplicationBuilder().token(config.BOT_TOKEN).build()
    
    # Commands
    app.add_handler(CommandHandler("start", cmd_start))
    app.add_handler(CommandHandler("help", cmd_help))
    app.add_handler(CommandHandler("clear", cmd_clear))
    app.add_handler(CommandHandler("stats", cmd_stats))
    app.add_handler(CommandHandler("img", cmd_img))
    app.add_handler(CommandHandler("code", cmd_code))
    app.add_handler(CommandHandler("vision", cmd_vision))
    app.add_handler(CommandHandler("weather", cmd_weather))
    app.add_handler(CommandHandler("news", cmd_news))
    app.add_handler(CommandHandler("exchange", cmd_exchange))
    app.add_handler(CommandHandler("time", cmd_time))
    app.add_handler(CommandHandler("translate", cmd_translate))
    app.add_handler(CommandHandler("sendfile", cmd_sendfile))
    app.add_handler(CommandHandler("cancelfile", cmd_cancelfile))
    
    # Callbacks
    app.add_handler(CallbackQueryHandler(on_callback_query))
    
    # Messages
    app.add_handler(MessageHandler(filters.PHOTO, on_photo))
    app.add_handler(MessageHandler(filters.Document.ALL, on_file))
    app.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, on_text))
    
    print("ğŸš€ Bot Ä‘ang cháº¡y...")
    print("ğŸ“¸ Vision: Gemini-1.5-Flash")
    print("ğŸ¨ Image Gen: Gemini-2.0-Flash")
    print("ğŸ’¬ Chat: Claude-3.5 via Vercel")
    print("ğŸ‘¨â€ğŸ’» Dev: @cucodoivandep")
    print("=" * 50)
    
    app.run_polling(drop_pending_updates=True)

if __name__ == "__main__":
    main()
