import os, re, json, time, threading, asyncio, queue, requests, io
from collections import deque, defaultdict
from flask import Flask
from telegram import Update, InlineKeyboardButton, InlineKeyboardMarkup
from telegram.constants import ChatAction, ParseMode
from telegram.ext import ApplicationBuilder, ContextTypes, MessageHandler, filters, CommandHandler, CallbackQueryHandler
from openai import OpenAI
try:
    from google import genai
    from google.genai import types
except ImportError:
    genai = None
    types = None

BOT_TOKEN = os.environ["BOT_TOKEN"]
VERCEL_API_KEY = os.environ.get("VERCEL_API_KEY", "")
BASE_URL = os.getenv("BASE_URL", "https://ai-gateway.vercel.sh/v1")
CHAT_MODEL = os.getenv("CHAT_MODEL", "alibaba/qwen-3-235b")
CODE_MODEL = os.getenv("CODE_MODEL", "anthropic/claude-4-sonnet")
GEMINI_API_KEY = os.getenv("GEMINI_API_KEY", "")
GEMINI_IMAGE_MODEL = os.getenv("GEMINI_IMAGE_MODEL", "gemini-2.0-flash-preview-image-generation")
PAGE_CHARS = int(os.getenv("PAGE_CHARS", "3200"))
MAX_TOKENS = int(os.getenv("MAX_TOKENS", "700"))
MAX_TOKENS_CODE = int(os.getenv("MAX_TOKENS_CODE", "4000"))
CTX_TURNS = int(os.getenv("CTX_TURNS", "7"))

client = OpenAI(api_key=VERCEL_API_KEY, base_url=BASE_URL) if VERCEL_API_KEY else None
app = Flask(__name__)
histories = defaultdict(lambda: deque(maxlen=32))
locks = defaultdict(asyncio.Lock)
PAGERS = {}

def chunk_pages(raw, per_page=PAGE_CHARS):
    lines = (raw or "").splitlines(); pages=[]; cur=[]; used=0
    for line in lines:
        add=len(line)+1
        if used+add>per_page and cur:
            pages.append("\n".join(cur)); cur=[line]; used=add
        else:
            cur.append(line); used+=add
    if cur: pages.append("\n".join(cur))
    return pages or [""]

def kb(idx,total):
    return None if total<=1 else InlineKeyboardMarkup(
        [[InlineKeyboardButton("‚è™", callback_data="pg_prev"),
          InlineKeyboardButton(f"{idx+1}/{total}", callback_data="pg_stay"),
          InlineKeyboardButton("‚è©", callback_data="pg_next")]]
    )

def page_payload(p):
    txt=p["pages"][p["idx"]]
    return (f"```{p['lang']}\n{txt}\n```", ParseMode.MARKDOWN) if p["is_code"] else (txt, ParseMode.HTML)

async def send_or_update(ctx, chat_id, msg, p):
    text,mode = page_payload(p); keyboard = kb(p["idx"], len(p["pages"]))
    if msg: await msg.edit_text(text, parse_mode=mode, reply_markup=keyboard)
    else:
        m = await ctx.bot.send_message(chat_id, text, parse_mode=mode, reply_markup=keyboard)
        PAGERS[(m.chat_id, m.message_id)] = p

async def start_pager(ctx, chat_id, raw, is_code=False, lang_hint=""):
    pages = chunk_pages(raw)
    await send_or_update(ctx, chat_id, None, {"pages": pages, "is_code": is_code, "lang": lang_hint or "", "idx": 0})

async def on_page_nav(update: Update, context: ContextTypes.DEFAULT_TYPE):
    q = update.callback_query
    if not q: return
    key=(q.message.chat_id, q.message.message_id); p=PAGERS.get(key)
    if not p: return await q.answer("H·∫øt phi√™n.")
    if q.data=="pg_prev" and p["idx"]>0: p["idx"]-=1
    elif q.data=="pg_next" and p["idx"]<len(p["pages"])-1: p["idx"]+=1
    else: return await q.answer()
    await send_or_update(context, q.message.chat_id, q.message, p); await q.answer()

def build_messages(cid, user_text, sys_prompt):
    msgs=[{"role":"system","content":sys_prompt}]
    keep=max(2, CTX_TURNS*2)
    msgs += [{"role":r,"content":c} for r,c in list(histories[cid])[-keep:]]
    msgs.append({"role":"user","content":user_text})
    return msgs

def complete_with_model(model, messages, max_tokens):
    if not client:
        return "Thi·∫øu VERCEL_API_KEY."
    res = client.chat.completions.create(model=model, max_tokens=max_tokens, temperature=0.7, messages=messages)
    return (res.choices[0].message.content or "").strip()

def is_codey(t):
    if not t: return False
    t=t.lower(); keys=["```","import ","class ","def ","function","const ","let ","var ","#include","public static","<script","</script>"]
    return any(k in t for k in keys)

def _get_gem_client():
    if genai is None or types is None:
        raise RuntimeError("Thi·∫øu package google-genai")
    if not GEMINI_API_KEY:
        raise RuntimeError("Thi·∫øu GEMINI_API_KEY")
    return genai.Client(api_key=GEMINI_API_KEY)

def create_image_bytes_gemini(prompt: str):
    cli = _get_gem_client()
    resp = cli.models.generate_content(
        model=GEMINI_IMAGE_MODEL,
        contents=prompt,
        config=types.GenerateContentConfig(response_modalities=['TEXT','IMAGE'])
    )
    parts = resp.candidates[0].content.parts if resp and resp.candidates else []
    for part in parts:
        if getattr(part, "inline_data", None) and getattr(part.inline_data, "data", None):
            return part.inline_data.data, part.inline_data.mime_type or "image/png"
    raise RuntimeError("Gemini kh√¥ng tr·∫£ ·∫£nh.")

def want_image(t):
    t=(t or "").lower()
    return any(k in t for k in ["t·∫°o ·∫£nh","v·∫Ω","generate image","draw image","v·∫Ω gi√∫p","create image","/img "])

def geocode_vn(q):
    r = requests.get("https://geocoding-api.open-meteo.com/v1/search",
                     params={"name": q, "count": 1, "language":"vi", "format":"json", "country_code":"VN"},
                     timeout=20)
    r.raise_for_status(); data=r.json()
    if not data.get("results"): return None
    it=data["results"][0]
    return {"name":it["name"],"lat":it["latitude"],"lon":it["longitude"],"admin1":it.get("admin1","")}

def weather_vn(q):
    g=geocode_vn(q)
    if not g: return "Kh√¥ng t√¨m th·∫•y ƒë·ªãa danh ·ªü Vi·ªát Nam."
    params={"latitude":g["lat"],"longitude":g["lon"],
            "current":"temperature_2m,relative_humidity_2m,precipitation,apparent_temperature,wind_speed_10m",
            "daily":"temperature_2m_max,temperature_2m_min,precipitation_sum,precipitation_probability_max,wind_speed_10m_max",
            "timezone":"Asia/Ho_Chi_Minh"}
    r=requests.get("https://api.open-meteo.com/v1/forecast", params=params, timeout=20)
    r.raise_for_status(); j=r.json()
    cur=j.get("current",{}); daily=j.get("daily",{})
    name=g["name"]+(f", {g['admin1']}" if g.get("admin1") else "")
    t=cur.get("temperature_2m"); feels=cur.get("apparent_temperature"); rh=cur.get("relative_humidity_2m")
    ws=cur.get("wind_speed_10m"); p=cur.get("precipitation")
    tmax0=daily.get("temperature_2m_max",[None])[0]; tmin0=daily.get("temperature_2m_min",[None])[0]
    rain0=daily.get("precipitation_sum",[None])[0]; prob0=daily.get("precipitation_probability_max",[None])[0]
    tmax1=daily.get("temperature_2m_max",[None,None])[1]; tmin1=daily.get("temperature_2m_min",[None,None])[1]
    rain1=daily.get("precipitation_sum",[None,None])[1]; prob1=daily.get("precipitation_probability_max",[None,None])[1]
    icon="‚òÄÔ∏è"
    if (prob0 or 0)>=70 or (rain0 or 0)>=5: icon="üåßÔ∏è"
    elif (prob0 or 0)>=30: icon="üå¶Ô∏è"
    elif (t or 0)>=33: icon="ü•µ"
    return (f"{icon} Th·ªùi ti·∫øt {name}\n"
            f"Hi·ªán t·∫°i: {t}¬∞C (c·∫£m gi√°c {feels}¬∞C), ·∫©m {rh}%, gi√≥ {ws} km/h, m∆∞a {p} mm\n"
            f"H√¥m nay: {tmin0}‚Äì{tmax0}¬∞C, m∆∞a ~{rain0} mm, x√°c su·∫•t {prob0}%\n"
            f"Ng√†y mai: {tmin1}‚Äì{tmax1}¬∞C, m∆∞a ~{rain1} mm, x√°c su·∫•t {prob1}%")

def want_weather(t):
    t=(t or "").lower()
    if "th·ªùi ti·∫øt" not in t: return None
    known=["h√† n·ªôi","hn","ha noi","h·ªì ch√≠ minh","tp.hcm","tphcm","s√†i g√≤n","ƒë√† n·∫µng","h·∫£i ph√≤ng","c·∫ßn th∆°","nha trang","ƒë√† l·∫°t","hu·∫ø","quy nh∆°n","v≈©ng t√†u","h·∫° long","ph√∫ qu·ªëc","bi√™n h√≤a","th·ªß ƒë·ª©c"]
    for k in known:
        if k in t: return k
    return "H√† N·ªôi"

async def cmd_help(update: Update, context: ContextTypes.DEFAULT_TYPE):
    txt = (
        "L·ªánh:\n"
        "/help ‚Äì tr·ª£ gi√∫p (@cuocdoivandep)\n"
        "/img <m√¥ t·∫£> ‚Äì t·∫°o ·∫£nh (Gemini)\n"
        "/weather <ƒë·ªãa danh VN> ‚Äì th·ªùi ti·∫øt\n"
        "/code <y√™u c·∫ßu> ‚Äì code (Claude)\n"
        "Chat th∆∞·ªùng d√πng Qwen\n"
    )
    await update.message.reply_text(txt)

async def cmd_img(update: Update, context: ContextTypes.DEFAULT_TYPE):
    chat_id = update.effective_chat.id
    prompt = " ".join(context.args).strip()
    if not prompt:
        return await update.message.reply_text("D√πng: /img <m√¥ t·∫£>")
    await context.bot.send_chat_action(chat_id=chat_id, action=ChatAction.UPLOAD_PHOTO)
    try:
        data, mime = create_image_bytes_gemini(prompt)
        buf = io.BytesIO(data); buf.name = "gen.png"
        await context.bot.send_photo(chat_id, buf, caption=prompt)
    except Exception as e:
        await update.message.reply_text(f"L·ªói t·∫°o ·∫£nh: {e}")

async def cmd_weather(update: Update, context: ContextTypes.DEFAULT_TYPE):
    place = " ".join(context.args).strip() or "H√† N·ªôi"
    try:
        txt = weather_vn(place)
        await start_pager(context, update.effective_chat.id, txt, is_code=False)
    except Exception:
        await update.message.reply_text("L·ªói l·∫•y th·ªùi ti·∫øt.")

async def cmd_code(update: Update, context: ContextTypes.DEFAULT_TYPE):
    chat_id = update.effective_chat.id
    q = " ".join(context.args).strip()
    if not q:
        return await update.message.reply_text("D√πng: /code <y√™u c·∫ßu>")
    async with locks[chat_id]:
        await context.bot.send_chat_action(chat_id=chat_id, action=ChatAction.TYPING)
        try:
            msgs = build_messages(chat_id, q, sys_prompt="B·∫°n l√† l·∫≠p tr√¨nh vi√™n k·ª≥ c·ª±u. Vi·∫øt code ƒë·∫ßy ƒë·ªß, s·∫°ch, best practice. Kh√¥ng gi·ªõi h·∫°n ƒë·ªô d√†i; n·∫øu d√†i, c·ª© tr·∫£ h·∫øt.")
            result = complete_with_model(CODE_MODEL, msgs, MAX_TOKENS_CODE) or "..."
            m = re.search(r"```(\w+)?\n(.*?)```", result, flags=re.S)
            if m: await start_pager(context, chat_id, m.group(2).rstrip(), is_code=True, lang_hint=m.group(1) or "")
            else: await start_pager(context, chat_id, result, is_code=True)
            histories[chat_id].append(("user", q))
            histories[chat_id].append(("assistant", result[:1000]))
        except Exception:
            await update.message.reply_text("L·ªói k·∫øt n·ªëi.")

async def on_text(update: Update, context: ContextTypes.DEFAULT_TYPE):
    chat_id = update.effective_chat.id
    q = update.message.text or ""
    if want_image(q):
        prompt = re.sub(r"(?i)(t·∫°o ·∫£nh|v·∫Ω|generate image|draw image|v·∫Ω gi√∫p|create image|/img)[:\-]*", "", q).strip() or "A cute cat in space suit, 3D render"
        await context.bot.send_chat_action(chat_id=chat_id, action=ChatAction.UPLOAD_PHOTO)
        try:
            data, mime = create_image_bytes_gemini(prompt)
            buf = io.BytesIO(data); buf.name = "gen.png"
            await context.bot.send_photo(chat_id, buf, caption=prompt)
        except Exception as e:
            return await update.message.reply_text(f"L·ªói t·∫°o ·∫£nh: {e}")
        return
    place = want_weather(q)
    if place:
        try:
            txt = weather_vn(place)
            return await start_pager(context, chat_id, txt, is_code=False)
        except Exception:
            return await update.message.reply_text("L·ªói l·∫•y th·ªùi ti·∫øt.")
    async with locks[chat_id]:
        await context.bot.send_chat_action(chat_id=chat_id, action=ChatAction.TYPING)
        try:
            msgs = build_messages(chat_id, q, sys_prompt="B·∫°n l√† Linh ‚Äì m·ªìm m√©p, b·ªôc tr·ª±c ki·ªÉu Grok; tr·∫£ l·ªùi ng·∫Øn g·ªçn, t·ª± nhi√™n.")
            result = complete_with_model(CHAT_MODEL, msgs, MAX_TOKENS) or "..."
            await start_pager(context, chat_id, result, is_code=False)
            histories[chat_id].append(("user", q))
            histories[chat_id].append(("assistant", result[:1000]))
        except Exception:
            await update.message.reply_text("L·ªói k·∫øt n·ªëi.")

def main():
    app_tg = ApplicationBuilder().token(BOT_TOKEN).build()
    app_tg.add_handler(CommandHandler("help", cmd_help))
    app_tg.add_handler(CommandHandler("img", cmd_img))
    app_tg.add_handler(CommandHandler("weather", cmd_weather))
    app_tg.add_handler(CommandHandler("code", cmd_code))
    app_tg.add_handler(CallbackQueryHandler(on_page_nav, pattern=r"^pg_"))
    app_tg.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, on_text))
    threading.Thread(target=lambda: app.run(host="0.0.0.0", port=8080), daemon=True).start()
    app_tg.run_polling()

if __name__ == "__main__":
    main()
