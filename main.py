import os, re, json, time, threading, asyncio, queue, requests, io, csv
from collections import deque, defaultdict
from flask import Flask
from telegram import Update, InlineKeyboardButton, InlineKeyboardMarkup
from telegram.constants import ChatAction, ParseMode
from telegram.ext import ApplicationBuilder, ContextTypes, MessageHandler, filters, CommandHandler, CallbackQueryHandler
from openai import OpenAI
try:
    from google import genai
    from google.genai import types
except ImportError:
    genai = None
    types = None
try:
    import PyPDF2
except Exception:
    PyPDF2 = None

BOT_TOKEN = os.environ["BOT_TOKEN"]
VERCEL_API_KEY = os.environ.get("VERCEL_API_KEY", "")
BASE_URL = os.getenv("BASE_URL", "https://ai-gateway.vercel.sh/v1")
CHAT_MODEL = os.getenv("CHAT_MODEL", "alibaba/qwen-3-235b")
CODE_MODEL = os.getenv("CODE_MODEL", "anthropic/claude-3.7-sonnet")
GEMINI_API_KEY = os.getenv("GEMINI_API_KEY", "")
GEMINI_IMAGE_MODEL = os.getenv("GEMINI_IMAGE_MODEL", "gemini-2.0-flash-preview-image-generation")
GEMINI_VISION_MODEL = os.getenv("GEMINI_VISION_MODEL", "gemini-2.0-flash-exp")
PAGE_CHARS = int(os.getenv("PAGE_CHARS", "3200"))
MAX_TOKENS = int(os.getenv("MAX_TOKENS", "700"))
MAX_TOKENS_CODE = int(os.getenv("MAX_TOKENS_CODE", "4000"))
CTX_TURNS = int(os.getenv("CTX_TURNS", "7"))

client = OpenAI(api_key=VERCEL_API_KEY, base_url=BASE_URL) if VERCEL_API_KEY else None
app = Flask(__name__)
histories = defaultdict(lambda: deque(maxlen=32))
locks = defaultdict(asyncio.Lock)
PAGERS = {}

def chunk_pages(raw, per_page=PAGE_CHARS):
    lines = (raw or "").splitlines(); pages=[]; cur=[]; used=0
    for line in lines:
        add=len(line)+1
        if used+add>per_page and cur:
            pages.append("\n".join(cur)); cur=[line]; used=add
        else:
            cur.append(line); used+=add
    if cur: pages.append("\n".join(cur))
    return pages or [""]

def kb(idx,total):
    return None if total<=1 else InlineKeyboardMarkup(
        [[InlineKeyboardButton("‚è™", callback_data="pg_prev"),
          InlineKeyboardButton(f"{idx+1}/{total}", callback_data="pg_stay"),
          InlineKeyboardButton("‚è©", callback_data="pg_next")]]
    )

def page_payload(p):
    txt=p["pages"][p["idx"]]
    return (f"```{p['lang']}\n{txt}\n```", ParseMode.MARKDOWN) if p["is_code"] else (txt, ParseMode.HTML)

async def send_or_update(ctx, chat_id, msg, p):
    text,mode = page_payload(p); keyboard = kb(p["idx"], len(p["pages"]))
    if msg: await msg.edit_text(text, parse_mode=mode, reply_markup=keyboard)
    else:
        m = await ctx.bot.send_message(chat_id, text, parse_mode=mode, reply_markup=keyboard)
        PAGERS[(m.chat_id, m.message_id)] = p

async def start_pager(ctx, chat_id, raw, is_code=False, lang_hint=""):
    pages = chunk_pages(raw)
    await send_or_update(ctx, chat_id, None, {"pages": pages, "is_code": is_code, "lang": lang_hint or "", "idx": 0})

async def on_page_nav(update: Update, context: ContextTypes.DEFAULT_TYPE):
    q = update.callback_query
    if not q: return
    key=(q.message.chat_id, q.message.message_id); p=PAGERS.get(key)
    if not p: return await q.answer("H·∫øt phi√™n.")
    if q.data=="pg_prev" and p["idx"]>0: p["idx"]-=1
    elif q.data=="pg_next" and p["idx"]<len(p["pages"])-1: p["idx"]+=1
    else: return await q.answer()
    await send_or_update(context, q.message.chat_id, q.message, p); await q.answer()

def build_messages(cid, user_text, sys_prompt):
    msgs=[{"role":"system","content":sys_prompt}]
    keep=max(2, CTX_TURNS*2)
    msgs += [{"role":r,"content":c} for r,c in list(histories[cid])[-keep:]]
    msgs.append({"role":"user","content":user_text})
    return msgs

def complete_with_model(model, messages, max_tokens):
    if not client:
        return "Thi·∫øu VERCEL_API_KEY."
    res = client.chat.completions.create(model=model, max_tokens=max_tokens, temperature=0.7, messages=messages)
    return (res.choices[0].message.content or "").strip()

def _get_gem_client():
    if genai is None or types is None:
        raise RuntimeError("Thi·∫øu package google-genai")
    if not GEMINI_API_KEY:
        raise RuntimeError("Thi·∫øu GEMINI_API_KEY")
    return genai.Client(api_key=GEMINI_API_KEY)

def create_image_bytes_gemini(prompt: str):
    cli = _get_gem_client()
    resp = cli.models.generate_content(
        model=GEMINI_IMAGE_MODEL,
        contents=prompt,
        config=types.GenerateContentConfig(response_modalities=['TEXT','IMAGE'])
    )
    parts = resp.candidates[0].content.parts if resp and resp.candidates else []
    for part in parts:
        if getattr(part, "inline_data", None) and getattr(part.inline_data, "data", None):
            return part.inline_data.data, part.inline_data.mime_type or "image/png"
    raise RuntimeError("Gemini kh√¥ng tr·∫£ ·∫£nh.")

def analyze_image_gemini(data: bytes, mime: str, user_hint: str = ""):
    cli = _get_gem_client()
    parts = [types.Part.from_bytes(data=data, mime_type=mime)]
    prompt = "M√¥ t·∫£ ·∫£nh chi ti·∫øt, n√™u b·ªëi c·∫£nh, h√†nh ƒë·ªông, ƒë·ªì v·∫≠t, ch·ªØ hi·ªÉn th·ªã n·∫øu ƒë·ªçc ƒë∆∞·ª£c. N√≥i ng·∫Øn g·ªçn, trung l·∫≠p, kh√¥ng kh·∫≥ng ƒë·ªãnh danh t√≠nh ng∆∞·ªùi th·∫≠t n·∫øu kh√¥ng ch·∫Øc. " + (user_hint or "")
    resp = cli.models.generate_content(model=GEMINI_VISION_MODEL, contents=[*parts, prompt])
    return resp.text.strip() if getattr(resp, "text", None) else "Kh√¥ng ph√¢n t√≠ch ƒë∆∞·ª£c ·∫£nh."

def geocode_vn(q):
    r = requests.get("https://geocoding-api.open-meteo.com/v1/search",
                     params={"name": q, "count": 1, "language":"vi", "format":"json", "country_code":"VN"},
                     timeout=20)
    r.raise_for_status(); data=r.json()
    if not data.get("results"): return None
    it=data["results"][0]
    return {"name":it["name"],"lat":it["latitude"],"lon":it["longitude"],"admin1":it.get("admin1","")}

def weather_vn(q):
    g=geocode_vn(q)
    if not g: return "Kh√¥ng t√¨m th·∫•y ƒë·ªãa danh ·ªü Vi·ªát Nam."
    params={"latitude":g["lat"],"longitude":g["lon"],
            "current":"temperature_2m,relative_humidity_2m,precipitation,apparent_temperature,wind_speed_10m",
            "daily":"temperature_2m_max,temperature_2m_min,precipitation_sum,precipitation_probability_max,wind_speed_10m_max",
            "timezone":"Asia/Ho_Chi_Minh"}
    r=requests.get("https://api.open-meteo.com/v1/forecast", params=params, timeout=20)
    r.raise_for_status(); j=r.json()
    cur=j.get("current",{}); daily=j.get("daily",{})
    name=g["name"]+(f", {g['admin1']}" if g.get("admin1") else "")
    t=cur.get("temperature_2m"); feels=cur.get("apparent_temperature"); rh=cur.get("relative_humidity_2m")
    ws=cur.get("wind_speed_10m"); p=cur.get("precipitation")
    tmax0=daily.get("temperature_2m_max",[None])[0]; tmin0=daily.get("temperature_2m_min",[None])[0]
    rain0=daily.get("precipitation_sum",[None])[0]; prob0=daily.get("precipitation_probability_max",[None])[0]
    tmax1=daily.get("temperature_2m_max",[None,None])[1]; tmin1=daily.get("temperature_2m_min",[None,None])[1]
    rain1=daily.get("precipitation_sum",[None,None])[1]; prob1=daily.get("precipitation_probability_max",[None,None])[1]
    icon="‚òÄÔ∏è"
    if (prob0 or 0)>=70 or (rain0 or 0)>=5: icon="üåßÔ∏è"
    elif (prob0 or 0)>=30: icon="üå¶Ô∏è"
    elif (t or 0)>=33: icon="ü•µ"
    return (f"{icon} Th·ªùi ti·∫øt {name}\n"
            f"Hi·ªán t·∫°i: {t}¬∞C (c·∫£m gi√°c {feels}¬∞C), ·∫©m {rh}%, gi√≥ {ws} km/h, m∆∞a {p} mm\n"
            f"H√¥m nay: {tmin0}‚Äì{tmax0}¬∞C, m∆∞a ~{rain0} mm, x√°c su·∫•t {prob0}%\n"
            f"Ng√†y mai: {tmin1}‚Äì{tmax1}¬∞C, m∆∞a ~{rain1} mm, x√°c su·∫•t {prob1}%")

def want_image(t):
    t=(t or "").lower()
    return any(k in t for k in ["t·∫°o ·∫£nh","v·∫Ω","generate image","draw image","v·∫Ω gi√∫p","create image","/img "])

def want_weather(t):
    t=(t or "").lower()
    if "th·ªùi ti·∫øt" not in t: return None
    known=["h√† n·ªôi","hn","ha noi","h·ªì ch√≠ minh","tp.hcm","tphcm","s√†i g√≤n","ƒë√† n·∫µng","h·∫£i ph√≤ng","c·∫ßn th∆°","nha trang","ƒë√† l·∫°t","hu·∫ø","quy nh∆°n","v≈©ng t√†u","h·∫° long","ph√∫ qu·ªëc","bi√™n h√≤a","th·ªß ƒë·ª©c"]
    for k in known:
        if k in t: return k
    return "H√† N·ªôi"

def guess_mime_from_name(name: str):
    n=name.lower()
    if n.endswith((".png",".jpg",".jpeg",".webp",".gif")): return "image"
    if n.endswith((".txt",".md",".json",".csv",".log")): return "text"
    if n.endswith(".pdf"): return "pdf"
    return "other"

def read_text_from_bytes(name: str, data: bytes, limit: int = 200_000):
    kind=guess_mime_from_name(name)
    if kind=="text":
        try:
            return data.decode("utf-8", errors="ignore")[:limit]
        except Exception:
            return data.decode("latin-1", errors="ignore")[:limit]
    if kind=="pdf":
        if not PyPDF2: return "Kh√¥ng c√≥ PyPDF2 ƒë·ªÉ ƒë·ªçc PDF."
        buf=io.BytesIO(data); r=PyPDF2.PdfReader(buf)
        parts=[]
        for i in range(min(len(r.pages), 50)):
            try:
                parts.append(r.pages[i].extract_text() or "")
            except Exception:
                parts.append("")
        return "\n".join(parts)[:limit] or "PDF kh√¥ng tr√≠ch ƒë∆∞·ª£c ch·ªØ."
    return None

async def cmd_help(update: Update, context: ContextTypes.DEFAULT_TYPE):
    txt = (
        "L·ªánh:\n"
        "/help ‚Äì H·ªó tr·ª£ l·ªánh\n"
        "/img <m√¥ t·∫£> ‚Äì t·∫°o ·∫£nh (Gemini)\n"
        "/weather <ƒë·ªãa danh VN> ‚Äì th·ªùi ti·∫øt\n"
        "/code <y√™u c·∫ßu> ‚Äì code (Claude)\n"
        "G·ª≠i ·∫£nh ƒë·ªÉ ph√¢n t√≠ch n·ªôi dung.\n"
        "G·ª≠i file .txt/.md/.json/.csv/.pdf ƒë·ªÉ ƒë·ªçc v√† t√≥m t·∫Øt.\n"
        "BOT ƒë∆∞·ª£c t·∫°o b·ªüi (@cuocdoivandep)\n"
    )
    await update.message.reply_text(txt)

async def cmd_img(update: Update, context: ContextTypes.DEFAULT_TYPE):
    chat_id = update.effective_chat.id
    prompt = " ".join(context.args).strip()
    if not prompt:
        return await update.message.reply_text("D√πng: /img <m√¥ t·∫£>")
    await context.bot.send_chat_action(chat_id=chat_id, action=ChatAction.UPLOAD_PHOTO)
    try:
        data, mime = create_image_bytes_gemini(prompt)
        buf = io.BytesIO(data); buf.name = "gen.png"
        await context.bot.send_photo(chat_id, buf, caption=prompt)
    except Exception as e:
        await update.message.reply_text(f"L·ªói t·∫°o ·∫£nh: {e}")

async def cmd_weather(update: Update, context: ContextTypes.DEFAULT_TYPE):
    place = " ".join(context.args).strip() or "H√† N·ªôi"
    try:
        txt = weather_vn(place)
        await start_pager(context, update.effective_chat.id, txt, is_code=False)
    except Exception:
        await update.message.reply_text("L·ªói l·∫•y th·ªùi ti·∫øt.")

async def cmd_code(update: Update, context: ContextTypes.DEFAULT_TYPE):
    chat_id = update.effective_chat.id
    q = " ".join(context.args).strip()
    if not q:
        return await update.message.reply_text("D√πng: /code <y√™u c·∫ßu>")
    async with locks[chat_id]:
        await context.bot.send_chat_action(chat_id=chat_id, action=ChatAction.TYPING)
        try:
            msgs = build_messages(chat_id, q, sys_prompt="B·∫°n l√† l·∫≠p tr√¨nh vi√™n k·ª≥ c·ª±u. Vi·∫øt code ƒë·∫ßy ƒë·ªß, s·∫°ch, best practice. Kh√¥ng gi·ªõi h·∫°n ƒë·ªô d√†i; n·∫øu d√†i, c·ª© tr·∫£ h·∫øt.")
            result = complete_with_model(CODE_MODEL, msgs, MAX_TOKENS_CODE) or "..."
            m = re.search(r"```(\w+)?\n(.*?)```", result, flags=re.S)
            if m: await start_pager(context, chat_id, m.group(2).rstrip(), is_code=True, lang_hint=m.group(1) or "")
            else: await start_pager(context, chat_id, result, is_code=True)
            histories[chat_id].append(("user", q))
            histories[chat_id].append(("assistant", result[:1000]))
        except Exception:
            await update.message.reply_text("L·ªói k·∫øt n·ªëi.")

async def on_text(update: Update, context: ContextTypes.DEFAULT_TYPE):
    chat_id = update.message.chat_id
    q = update.message.text or ""
    if want_image(q):
        prompt = re.sub(r"(?i)(t·∫°o ·∫£nh|v·∫Ω|generate image|draw image|v·∫Ω gi√∫p|create image|/img)[:\-]*", "", q).strip() or "A cute cat in space suit, 3D render"
        await context.bot.send_chat_action(chat_id=chat_id, action=ChatAction.UPLOAD_PHOTO)
        try:
            data, mime = create_image_bytes_gemini(prompt)
            buf = io.BytesIO(data); buf.name = "gen.png"
            await context.bot.send_photo(chat_id, buf, caption=prompt)
        except Exception as e:
            return await update.message.reply_text(f"L·ªói t·∫°o ·∫£nh: {e}")
        return
    place = want_weather(q)
    if place:
        try:
            txt = weather_vn(place)
            return await start_pager(context, chat_id, txt, is_code=False)
        except Exception:
            return await update.message.reply_text("L·ªói l·∫•y th·ªùi ti·∫øt.")
    async with locks[chat_id]:
        await context.bot.send_chat_action(chat_id=chat_id, action=ChatAction.TYPING)
        try:
            msgs = build_messages(chat_id, q, sys_prompt="B·∫°n l√† Linh ‚Äì m·ªìm m√©p, b·ªôc tr·ª±c ki·ªÉu Grok; tr·∫£ l·ªùi ng·∫Øn g·ªçn, t·ª± nhi√™n.")
            result = complete_with_model(CHAT_MODEL, msgs, MAX_TOKENS) or "..."
            await start_pager(context, chat_id, result, is_code=False)
            histories[chat_id].append(("user", q))
            histories[chat_id].append(("assistant", result[:1000]))
        except Exception:
            await update.message.reply_text("L·ªói k·∫øt n·ªëi.")

async def on_photo(update: Update, context: ContextTypes.DEFAULT_TYPE):
    chat_id = update.effective_chat.id
    await context.bot.send_chat_action(chat_id=chat_id, action=ChatAction.TYPING)
    try:
        ph = update.message.photo[-1]
        f = await context.bot.get_file(ph.file_id)
        bio = io.BytesIO()
        await f.download_to_memory(out=bio)
        data=bio.getvalue()
        desc = analyze_image_gemini(data, "image/jpeg")
        await start_pager(context, chat_id, desc, is_code=False)
    except Exception as e:
        await update.message.reply_text(f"L·ªói ph√¢n t√≠ch ·∫£nh: {e}")

async def on_file(update: Update, context: ContextTypes.DEFAULT_TYPE):
    chat_id = update.effective_chat.id
    doc = update.message.document
    name = doc.file_name or "file"
    await context.bot.send_chat_action(chat_id=chat_id, action=ChatAction.TYPING)
    try:
        f = await context.bot.get_file(doc.file_id)
        bio = io.BytesIO()
        await f.download_to_memory(out=bio)
        data=bio.getvalue()
        kind = guess_mime_from_name(name)
        if kind=="image":
            desc = analyze_image_gemini(data, doc.mime_type or "image/*")
            return await start_pager(context, chat_id, f"·∫¢nh: {name}\n\n{desc}", is_code=False)
        text = read_text_from_bytes(name, data)
        if text is None:
            return await update.message.reply_text("File n√†y ch∆∞a h·ªó tr·ª£. Th·ª≠ .txt/.md/.json/.csv/.pdf ho·∫∑c g·ª≠i ·∫£nh.")
        sys = "T·ª´ n·ªôi dung sau, t√≥m t·∫Øt g·ªçn, n√™u m·ª•c ch√≠nh, li·ªát k√™ d·ªØ ki·ªán quan tr·ªçng, ch·ªâ ra ƒëi·ªÉm b·∫•t th∆∞·ªùng n·∫øu c√≥."
        msgs = [{"role":"system","content":sys},{"role":"user","content":text[:15000]}]
        summary = complete_with_model(CHAT_MODEL, msgs, MAX_TOKENS) if client else text[:PAGE_CHARS]
        await start_pager(context, chat_id, f"T√≥m t·∫Øt {name}:\n\n{summary}", is_code=False)
    except Exception as e:
        await update.message.reply_text(f"L·ªói ƒë·ªçc file: {e}")

def main():
    app_tg = ApplicationBuilder().token(BOT_TOKEN).build()
    app_tg.add_handler(CommandHandler("help", cmd_help))
    app_tg.add_handler(CommandHandler("img", cmd_img))
    app_tg.add_handler(CommandHandler("weather", cmd_weather))
    app_tg.add_handler(CommandHandler("code", cmd_code))
    app_tg.add_handler(CallbackQueryHandler(on_page_nav, pattern=r"^pg_"))
    app_tg.add_handler(MessageHandler(filters.PHOTO, on_photo))
    app_tg.add_handler(MessageHandler(filters.Document.ALL, on_file))
    app_tg.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, on_text))
    threading.Thread(target=lambda: app.run(host="0.0.0.0", port=8080), daemon=True).start()
    app_tg.run_polling()

if __name__ == "__main__":
    main()
